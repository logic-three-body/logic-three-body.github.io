<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://logic-three-body.github.io/</id>
    <title>Gridea</title>
    <updated>2021-06-18T09:01:01.101Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://logic-three-body.github.io/"/>
    <link rel="self" href="https://logic-three-body.github.io/atom.xml"/>
    <subtitle>温故而知新</subtitle>
    <logo>https://logic-three-body.github.io/images/avatar.png</logo>
    <icon>https://logic-three-body.github.io/favicon.ico</icon>
    <rights>All rights reserved 2021, Gridea</rights>
    <entry>
        <title type="html"><![CDATA[GAMES202 -> assignment2 precoumpute radiance transfer]]></title>
        <id>https://logic-three-body.github.io/post/assignment2-precoumpute-radiance-transfer/</id>
        <link href="https://logic-three-body.github.io/post/assignment2-precoumpute-radiance-transfer/">
        </link>
        <updated>2021-06-18T08:33:22.000Z</updated>
        <content type="html"><![CDATA[<p>项目地址：<a href="https://github.com/logic-three-body/GAMES202_HQRTR/tree/master/Assignment2">here</a></p>
<p>//TODO add context</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[GAMES202 -> assignment3 screen space raytracing]]></title>
        <id>https://logic-three-body.github.io/post/assignment3-screen-space-raytracing/</id>
        <link href="https://logic-three-body.github.io/post/assignment3-screen-space-raytracing/">
        </link>
        <updated>2021-06-18T08:31:13.000Z</updated>
        <content type="html"><![CDATA[<h2 id="evaldir">EvalDir</h2>
<pre><code class="language-glsl">vec3 EvalDirectionalLight(vec2 uv) {
  vec3 lightDirWS = normalize(uLightDir);
  vec3 normalWS = normalize(GetGBufferNormalWorld(uv));
  float ndotl = max(0.0,dot(lightDirWS,normalWS));
  float visibility = GetGBufferuShadow(uv);
  Le = uLightRadiance * visibility * ndotl;
  return Le;
}
</code></pre>
<figure data-type="image" tabindex="1"><img src="https://i.loli.net/2021/06/05/dr3AWa9bjVmhvEJ.gif" alt="dir_only" loading="lazy"></figure>
<h2 id="evaldiffuse">EvalDiffuse</h2>
<pre><code class="language-glsl">vec3 EvalDiffuse(vec3 wi, vec3 wo, vec2 uv) {
  vec3 normal = normalize(GetGBufferNormalWorld(uv));
  vec3 diff = GetGBufferDiffuse(uv);
  float cosTheta = dot(normalize(wi),normal);
  vec3 L = diff * INV_PI * cosTheta;
  return L;
}
</code></pre>
<p>main：</p>
<pre><code class="language-glsl">vec3 worldPos = vPosWorld.xyz;
vec2 uv0 = GetScreenCoordinate(worldPos);
vec3 wi = normalize(uLightDir);
vec3 wo = normalize(uCameraPos - worldPos);
float scale = 5.0;
vec3 dirL = EvalDirectionalLight(uv0);
L+=dirL*EvalDiffuse(wi,wo,uv0)*scale;
</code></pre>
<figure data-type="image" tabindex="2"><img src="https://i.loli.net/2021/06/05/73yn8sEIHYKA2LN.gif" alt="dir+Diff" loading="lazy"></figure>
<h2 id="raymarch">RayMarch</h2>
<pre><code class="language-glsl">bool RayMarch(vec3 ori, vec3 dir, out vec3 hitPos) {
  vec2 ori_uv = GetScreenCoordinate(ori);
  vec2 dir_uv = GetScreenCoordinate(dir);
  float step_size = 2.0/float(total_step)/length(dir_uv);
  
  const int first_step=1;
  for(int i = first_step;i&lt;=total_step;++i)
  { 
    vec3 pos = ori+dir*step_size*float(i);
    vec2 pos_uv = GetScreenCoordinate(pos);
    if(GetGBufferDepth(pos_uv)+EPS&lt;GetDepth(pos))
    {
      hitPos = pos;
      return true;
    }
  }
 // hitPos = vec3(normalize(dir_uv),0.0);
  return false;
}
</code></pre>
<p>镜面反射查询</p>
<pre><code class="language-glsl">  //test mirro:
  vec3 test_dir = vec3(0.0);
  test_dir=reflect(-wo,normal);
  vec3 test_hit;
  if(RayMarch(worldPos,test_dir,test_hit))
  {
    indir = GetGBufferDiffuse(GetScreenCoordinate(test_hit));    
  }
</code></pre>
<figure data-type="image" tabindex="3"><img src="https://i.loli.net/2021/06/06/3bDSpK4ZitxrJwe.gif" alt="镜面反射handin" loading="lazy"></figure>
<p>间接光着色（spp=1）</p>
<pre><code class="language-glsl">  //indir shading:
  for(int i=0;i&lt;SAMPLE_NUM;++i)
  {
    float pdf=0.0;
    vec3 dir=SampleHemisphereUniform(s,pdf);
    //vec3 dir=SampleHemisphereCos(s,pdf);
    dir = dirToWorld(normal,dir);
    vec3 hitPos=vec3(0.0);
    vec3 direct = normalize(vec3(1.0,0.0,0.0));
    direct = normalize(dir);
    if(RayMarch(worldPos,direct,hitPos))
    {
      vec2 uv1=GetScreenCoordinate(hitPos);
      if(length(res)&gt;0.0) 
        indir += res;//avoid neg   
    }
  }
</code></pre>
<figure data-type="image" tabindex="4"><img src="https://i.loli.net/2021/06/06/tEuHrnKIZAs74iN.gif" alt="间接光" loading="lazy"></figure>
<h2 id="其他图片结果">其他图片结果</h2>
<h3 id="cube2">cube2</h3>
<h4 id="直接光">直接光</h4>
<h4 id=""><img src="https://i.loli.net/2021/06/06/8hXzv7RuApMOfjB.png" alt="直接光cube" loading="lazy"></h4>
<h4 id="间接光spp100">间接光spp=100</h4>
<h4 id="-2"><img src="https://i.loli.net/2021/06/06/ALowkM8OFeQZdyX.png" alt="间接光cube" loading="lazy"></h4>
<h4 id="直接光间接光spp100">直接光+间接光spp=100</h4>
<h4 id="-3"><img src="https://i.loli.net/2021/06/06/6lno4VzcE3PiewF.png" alt="直接光+间接光cube" loading="lazy"></h4>
<h3 id="cave">cave</h3>
<h4 id="直接光-2">直接光</h4>
<figure data-type="image" tabindex="5"><img src="https://i.loli.net/2021/06/06/pAMqtfR1lL4cFU3.png" alt="直接光cave" loading="lazy"></figure>
<h4 id="间接光spp100-2">间接光spp=100</h4>
<p>【说明：为了显示明显，仅显示间接光时将间接光强度进行了增大】</p>
<figure data-type="image" tabindex="6"><img src="https://i.loli.net/2021/06/06/j2kNBTYmoV6M3fO.png" alt="间接光cave" loading="lazy"></figure>
<h4 id="直接光间接光spp100-2">直接光+间接光spp=100</h4>
<figure data-type="image" tabindex="7"><img src="https://i.loli.net/2021/06/06/mAnztkgGE7IOZ39.png" alt="直接光+间接光cave" loading="lazy"></figure>
<h2 id="主函数-main">主函数 main</h2>
<pre><code class="language-glsl">vec3 dirToWorld(vec3 normal,vec3 localDir)
{
  vec3 b1=vec3(0.0);
  vec3 b2=vec3(0.0);
  LocalBasis(normal,b1,b2);
  mat3 tbn = mat3(b1,b2,normal);
  return tbn*localDir;
}
</code></pre>
<pre><code class="language-glsl">void main() {
  float s = InitRand(gl_FragCoord.xy);
  vec3 L = vec3(0.0);
  vec3 worldPos = vPosWorld.xyz;
  vec2 uv0 = GetScreenCoordinate(worldPos);
  vec3 dirL = EvalDirectionalLight(uv0);
  //L = GetGBufferDiffuse(uv0);
  vec3 wi = normalize(uLightDir);
  vec3 wo = normalize(uCameraPos - worldPos);
  float scale = 5.0;
  L+=dirL*EvalDiffuse(wi,wo,uv0)*scale;
  //L = dirL/scale;
  vec3 normal = GetGBufferNormalWorld(uv0);
  //raymarch:
  vec3 indir=vec3(0.0);

  //test mirro:
  // vec3 test_dir = vec3(0.0);
  // test_dir=reflect(-wo,normal);
  // vec3 test_hit;
  // if(RayMarch(worldPos,test_dir,test_hit))
  // {
  //   indir = GetGBufferDiffuse(GetScreenCoordinate(test_hit));    
  // }


  //indir shading:
  for(int i=0;i&lt;SAMPLE_NUM;++i)
  {
    float pdf=0.0;
    vec3 dir=SampleHemisphereUniform(s,pdf);
    //vec3 dir=SampleHemisphereCos(s,pdf);
    dir = dirToWorld(normal,dir);
    vec3 brdf0 = EvalDiffuse(wi,wo,uv0)/pdf;
    vec3 hitPos=vec3(0.0);
    vec3 direct = normalize(vec3(1.0,0.0,0.0));
    direct = normalize(dir);
    if(RayMarch(worldPos,direct,hitPos))
    {
      vec2 uv1=GetScreenCoordinate(hitPos);
      vec3 res = brdf0*EvalDiffuse(-wi,vec3(0.0),uv1)
                 *EvalDirectionalLight(uv1);      
      //vec3 res = EvalDiffuse(-direct,vec3(0.0),uv1);
      if(length(res)&gt;0.0) 
        indir += res;//avoid neg   
    }
  }
  indir/=float(SAMPLE_NUM);
  //L= indir*10.0;
  L+=indir;
  vec3 color = pow(clamp(L, vec3(0.0), vec3(1.0)), vec3(1.0 / 2.2));
  //color=vec3(0.6);
  gl_FragColor = vec4(vec3(color.rgb), 1.0);
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[WebGL three.js-example 研究 ->WebGL shader 实现Phong光照模型]]></title>
        <id>https://logic-three-body.github.io/post/webgl-shader-shi-xian-phong-guang-zhao-mo-xing/</id>
        <link href="https://logic-three-body.github.io/post/webgl-shader-shi-xian-phong-guang-zhao-mo-xing/">
        </link>
        <updated>2021-06-18T08:17:31.000Z</updated>
        <content type="html"><![CDATA[<h2 id="前言">前言</h2>
<p>之前里利用<a href="https://logic-three-body.github.io/post/threejs-shader-shi-xian-phong-guang-zhao-mo-xing/">Three.js</a>实现过Phong光照模型，也在<a href="https://github.com/logic-three-body/GAMES202_HQRTR/tree/master/homework0/src/shaders/phongShader">GAMES202作业0</a>接触过phong shader，这次更接近底层，利用WebGL实现一个简易的Phong光照模型</p>
<p>项目工程：<a href="https://github.com/logic-three-body/ThreeJSLearn/blob/master/WebGL/WebGL_Guide_Code/ch08/LightedTranslatedRotatedCube.js">here</a></p>
<h2 id="实现">实现</h2>
<h3 id="数据的传递">数据的传递</h3>
<p>立方体数据：顶点 顶点索引 法线 颜色</p>
<pre><code class="language-js">  // Create a cube
  //    v6----- v5
  //   /|      /|
  //  v1------v0|
  //  | |     | |
  //  | |v7---|-|v4
  //  |/      |/
  //  v2------v3

// Coordinates
var vertices = new Float32Array([
    1.0, 1.0, 1.0, -1.0, 1.0, 1.0, -1.0, -1.0, 1.0, 1.0, -1.0, 1.0,     // v0-v1-v2-v3 front
    1.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0, -1.0, -1.0, 1.0, 1.0, -1.0,     // v0-v3-v4-v5 right
    1.0, 1.0, 1.0, 1.0, 1.0, -1.0, -1.0, 1.0, -1.0, -1.0, 1.0, 1.0,     // v0-v5-v6-v1 up
    -1.0, 1.0, 1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, // v1-v6-v7-v2 left
    -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, 1.0, -1.0, 1.0, -1.0, -1.0, 1.0, // v7-v4-v3-v2 down
    1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 1.0, 1.0, -1.0  // v4-v7-v6-v5 back
]);

// Colors
var colors = new Float32Array([
    1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, // v0-v1-v2-v3 front
    1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, // v0-v3-v4-v5 right
    1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, // v0-v5-v6-v1 up
    1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, // v1-v6-v7-v2 left
    1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, // v7-v4-v3-v2 down
    1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0  // v4-v7-v6-v5 back
]);

// Normal
var normals = new Float32Array([
    0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0,     // v0-v1-v2-v3 front
    1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0,     // v0-v3-v4-v5 right
    0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0,     // v0-v5-v6-v1 up
    -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, // v1-v6-v7-v2 left
    0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, // v7-v4-v3-v2 down
    0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0  // v4-v7-v6-v5 back
]);

// Indices of the vertices
var indices = new Uint8Array([
    0, 1, 2, 0, 2, 3,       // front
    4, 5, 6, 4, 6, 7,       // right
    8, 9, 10, 8, 10, 11,    // up
    12, 13, 14, 12, 14, 15, // left
    16, 17, 18, 16, 18, 19, // down
    20, 21, 22, 20, 22, 23  // back
]);
</code></pre>
<p>准备传入shader的数据</p>
<pre><code class="language-js">// Get the storage locations of uniform variables
var u_MvpMatrix = gl.getUniformLocation(gl.program, 'u_MvpMatrix');
var u_NormalMatrix = gl.getUniformLocation(gl.program, 'u_NormalMatrix');
var u_LightColor = gl.getUniformLocation(gl.program, 'u_LightColor');
var u_LightDirection = gl.getUniformLocation(gl.program, 'u_LightDirection');
var u_AmbientLight = gl.getUniformLocation(gl.program, 'u_AmbientLight');
var u_CameraPosition = gl.getUniformLocation(gl.program, 'u_CameraPosition');
</code></pre>
<p>设置光源方向以及环境光颜色</p>
<pre><code class="language-js">// Set the light color (white)
gl.uniform3f(u_LightColor, 1.0, 1.0, 1.0);
// Set the light direction (in the world coordinate)
var lightDirection = new Vector3([ 0.0, 3.0, 4.0 ]);
lightDirection.normalize(); // Normalize
gl.uniform3fv(u_LightDirection, lightDirection.elements);
// Set the ambient light
gl.uniform3f(u_AmbientLight, 0.2, 0.2, 0.2);
</code></pre>
<p>设置相机视角位置</p>
<pre><code class="language-js">//Set Camera parm
var g_eyeX = 3,
    g_eyeY = 3,
    g_eyeZ = 7; // Eye position
var CameraPos = new Vector3(g_eyeX, g_eyeY, g_eyeZ);
gl.uniform3fv(u_CameraPosition, CameraPos.elements);
</code></pre>
<p>渲染函数</p>
<pre><code class="language-js">function draw(gl, u_MvpMatrix, mvpMatrix, normalMatrix, modelMatrix, u_NormalMatrix, n) {
  mvpMatrix.multiply(modelMatrix);
  gl.uniformMatrix4fv(u_MvpMatrix, false, mvpMatrix.elements);
  // Calculate the matrix to transform the normal based on the model matrix
  normalMatrix.setInverseOf(modelMatrix);
  normalMatrix.transpose();
  // Pass the transformation matrix for normals to u_NormalMatrix
  gl.uniformMatrix4fv(u_NormalMatrix, false, normalMatrix.elements);
  // Clear color and depth buffer
  gl.clear(gl.COLOR_BUFFER_BIT | gl.DEPTH_BUFFER_BIT);
  // Draw the cube
  gl.drawElements(gl.TRIANGLES, n, gl.UNSIGNED_BYTE, 0);
}
</code></pre>
<h4 id="model矩阵">model矩阵</h4>
<p>可利用键盘控制model矩阵以控制物体旋转与平移（类比<a href="https://github.com/logic-three-body/GameS101_IntroductionTOcomputerGraph/tree/%E4%BD%9C%E4%B8%9A1/Roate_Project">GAMES101作业1</a>）</p>
<p>最开始立方体先绕Z轴旋转90度</p>
<pre><code class="language-js">modelMatrix.rotate(90, 0, 0, 1); // Rotate 90 degree around the z-axis
function keydown(ev, gl, u_MvpMatrix, mvpMatrix, normalMatrix, modelMatrix, u_NormalMatrix, n)
{
    var move = 0.01;
    var angle = 1;
    if (ev.keyCode == 39) // The right arrow key was pressed
    {
        console.log(&quot;PRESS 39&quot;);
        modelMatrix.setTranslate(0, -move, 0); // right arrow
    }
    else if (ev.keyCode == 37)
    {
        console.log(&quot;PRESS 37&quot;);
        modelMatrix.setTranslate(0, move, 0); // left arrow
    }
    else if (ev.keyCode == 40) // down arrow
    {
        console.log(&quot;PRESS 40&quot;);
        modelMatrix.setTranslate(-move, 0, 0);
    }
    else if (ev.keyCode == 38) // down arrow
    {
        console.log(&quot;PRESS 38&quot;);
        modelMatrix.setTranslate(move, 0, 0);
    }
    else if (ev.keyCode == 68) // down D
    {
        modelMatrix.rotate(90 + angle, 0, 0, 1); // left arrow
        console.log(&quot;PRESS D&quot;);
    }
    else if (ev.keyCode == 65) // down A
    {
        console.log(&quot;PRESS A&quot;);
        modelMatrix.rotate(90 - angle, 0, 0);
    }
    else if (ev.keyCode == 87) // down W
    {
        modelMatrix.rotate(90 + angle, 0, 1, 0); // left arrow
        console.log(&quot;PRESS W&quot;);
    }
    else if (ev.keyCode == 83) // down S
    {
        console.log(&quot;PRESS S&quot;);
        modelMatrix.rotate(90 - angle, 0, 1, 0);
    }
    else
    {
        return;
    }
    draw(gl, u_MvpMatrix, mvpMatrix, normalMatrix, modelMatrix, u_NormalMatrix, n);
}
</code></pre>
<h4 id="mvp矩阵">mvp矩阵</h4>
<p>设置view视角矩阵和projection投影矩阵 (p * v * m * vertexdata)</p>
<pre><code class="language-js">// Calculate the view projection matrix
mvpMatrix.setPerspective(30, canvas.width / canvas.height, 1, 100);//projection
mvpMatrix.lookAt(g_eyeX, g_eyeY, g_eyeZ, 0, 0, 0, 0, 1, 0);//view
//...some code
mvpMatrix.multiply(modelMatrix);
</code></pre>
<h4 id="法线矩阵的处理">法线矩阵的处理</h4>
<p>法线变换推到过程：请参考Unityshader入门精要/第四章/4.7 法线变换</p>
<p>这里给出结论：法线变换矩阵 = 原变换矩阵逆转置</p>
<figure data-type="image" tabindex="1"><img src="https://i.loli.net/2021/06/18/zYo4Z5sefLcPkXr.png" alt="image-20210618145246902" loading="lazy"></figure>
<pre><code class="language-js">// Calculate the matrix to transform the normal based on the model matrix
normalMatrix.setInverseOf(modelMatrix);
normalMatrix.transpose();
// Pass the transformation matrix for normals to u_NormalMatrix
gl.uniformMatrix4fv(u_NormalMatrix, false, normalMatrix.elements);
</code></pre>
<h3 id="shader实现">shader实现</h3>
<p>Phong光照模型实现的三要素：环境光+漫反射+高光，其中高光实现难度相对较大，需要利用视角方向和光源反射方向</p>
<pre><code class="language-js">// Vertex shader program
var VSHADER_SOURCE =
  'attribute vec4 a_Position;\n' +
  'attribute vec4 a_Color;\n' +
  'attribute vec4 a_Normal;\n' +
  'uniform mat4 u_MvpMatrix;\n' +
  'uniform mat4 u_NormalMatrix;\n' + // Transformation matrix of the normal
  'uniform vec3 u_LightColor;\n' + // Light color
  'uniform vec3 u_LightDirection;\n' + // Light direction (in the world coordinate, normalized)
  'uniform vec3 u_AmbientLight;\n' + // Ambient light color
  'uniform vec3 u_CameraPosition;\n' +
  'varying vec4 v_Color;\n' +
  'void main() {\n' +
  '  gl_Position = u_MvpMatrix * a_Position;\n' +
  // Recalculate the normal based on the model matrix and make its length 1.
  '  vec3 normal = normalize(vec3(u_NormalMatrix * a_Normal));\n' +
  // Calculate the dot product of the light direction and the orientation of a surface (the normal)
  '  float nDotL = max(dot(u_LightDirection, normal), 0.0);\n' +
  // Calculate the color due to diffuse reflection
  '  vec3 diffuse = u_LightColor * a_Color.rgb * nDotL;\n' +
  // Calculate the color due to ambient reflection
  '  vec3 ambient = u_AmbientLight * a_Color.rgb;\n' +
  //Calculate view direct
  ' vec3 viewDir = normalize(u_CameraPosition - gl_Position.xyz);' +
  //Calculate reflect direct
  ' vec3 reflectDir = reflect(u_LightDirection,normal);' +
  //Calculate specular
  'float spec =pow (max(dot(viewDir, reflectDir), 0.0), 35.0);' +
  'vec3 specular = u_LightColor*spec*4.0;' +
  //Add the surface colors due to diffuse reflection and ambient reflection and our specular for phong
  '  v_Color = vec4(diffuse + ambient + specular, a_Color.a);\n' +
  '}\n';

// Fragment shader program
var FSHADER_SOURCE =
  '#ifdef GL_ES\n' +
  'precision mediump float;\n' +
  '#endif\n' +
  'varying vec4 v_Color;\n' +
  'void main() {\n' +
  '  gl_FragColor = v_Color;\n' +
  '}\n';
</code></pre>
<h2 id="结果图">结果图</h2>
<figure data-type="image" tabindex="2"><img src="https://i.loli.net/2021/06/18/6EbAJpvYBcTsCI8.gif" alt="phong模型2" loading="lazy"></figure>
<h2 id="参考">参考</h2>
<p>WebGL权威指南/第八章/示例程序（LightedTranslatedRotatedCube）</p>
<p>WebGL权威指南/第八章/魔法矩阵：逆转置矩阵</p>
<p>WebGL权威指南/第七章/示例程序（LookAtTrianglesWithKeys）</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[GAMES101->assignment1 Transform]]></title>
        <id>https://logic-three-body.github.io/post/games101-greaterassignment1-transform/</id>
        <link href="https://logic-three-body.github.io/post/games101-greaterassignment1-transform/">
        </link>
        <updated>2021-06-18T07:08:56.000Z</updated>
        <content type="html"><![CDATA[<h1 id="作业1-旋转与投影">作业1 旋转与投影</h1>
<h2 id="模型矩阵">模型矩阵</h2>
<pre><code class="language-C++">Eigen::Matrix4f get_model_matrix(float rotation_angle)
{
	Eigen::Matrix4f model = Eigen::Matrix4f::Identity();

	// TODO: Implement this function
	// Create the model matrix for rotating the triangle around the Z axis.
	// Then return it.
	Eigen::Matrix4f rotateZ, rotateY, rotateX, scaleK, translateX, translateZ;
	float angle = rotation_angle / 180 * MY_PI;
	//rotate with z
	rotateZ &lt;&lt; std::cos(angle), -1 * std::sin(angle), 0, 0, \
		std::sin(angle), std::cos(angle), 0, 0, \
		0, 0, 1, 0, \
		0, 0, 0, 1;
	//rotate with x
	rotateX &lt;&lt; 1, 0, 0, 0, \
		0, std::cos(angle), -std::sin(angle), 0, \
		0, std::sin(angle), std::cos(angle), 0, \
		0, 0, 0, 1;
	//rotate with y
	rotateY &lt;&lt; std::cos(angle), 0, std::sin(angle), 0, \
		0, 1, 0, 0, \
		- std::sin(angle), 0, std::cos(angle), 0, \
		0, 0, 0, 1;

	//scale with k
	float k = .01;//scale factor
	scaleK &lt;&lt; k , 0, 0, 0, \
		0, k, 0, 0, \
		0, 0, k , 0, \
		0, 0, 0, 1;

	//translate X OR Z for any step
	float step = -angle / 10.0;
	translateX &lt;&lt; 1, 0, 0, step, \
		0, 1, 0, 0, \
		0, 0, 1, 0, \
		0, 0, 0, 1;

	translateZ &lt;&lt; 1, 0, 0, 0, \
		0, 1, 0, 0, \
		0, 0, 1, step, \
		0, 0, 0, 1;
	model = rotateZ * model;
	//model = rotateX * model;
	//model = rotateY * model;
	//model = scaleK * model;
	//model *= translateX;
	//model *= translateZ;
	//model *= translateX*rotateX*scaleK;
	//model *= rotateZ * scaleK;
	//model *= rotateY * scaleK;
	return model;
}
</code></pre>
<h2 id="透视投影矩阵">透视投影矩阵</h2>
<pre><code class="language-C++">Eigen::Matrix4f get_projection_matrix(float eye_fov, float aspect_ratio, float zNear, float zFar)
{
	Eigen::Matrix4f projection = Eigen::Matrix4f::Identity();
	Eigen::Matrix4f M_persp2ortho(4, 4);
	Eigen::Matrix4f M_ortho_scale(4, 4);
	Eigen::Matrix4f M_ortho_trans(4, 4);

	float angle = eye_fov * MY_PI / 180.0; // half angle
	float height = zNear * tan(angle) * 2;
	float width = height * aspect_ratio;

	auto t = -zNear * tan(angle / 2);
	auto r = t * aspect_ratio;
	auto l = -r;
	auto b = -t;

	M_persp2ortho &lt;&lt; zNear, 0, 0, 0,
		0, zNear, 0, 0,
		0, 0, zNear + zFar, -zNear * zFar,
		0, 0, 1, 0;

	M_ortho_scale &lt;&lt; 2 / (r - l), 0, 0, 0,
		0, 2 / (t - b), 0, 0,
		0, 0, 2 / (zNear - zFar), 0,
		0, 0, 0, 1;

	M_ortho_trans &lt;&lt; 1, 0, 0, -(r + l) / 2,
		0, 1, 0, -(t + b) / 2,
		0, 0, 1, -(zNear + zFar) / 2,
		0, 0, 0, 1;

	Eigen::Matrix4f M_ortho = M_ortho_scale * M_ortho_trans;
	//prespective
	projection = M_ortho * M_persp2ortho * projection;

	//orthogonal
	//projection *= M_ortho;

	return projection;
}
</code></pre>
<h2 id="三角形旋转">三角形旋转</h2>
<h3 id="绕z轴">绕Z轴</h3>
<pre><code class="language-c++">rotateZ &lt;&lt; std::cos(angle), -1 * std::sin(angle), 0, 0,
    std::sin(angle), std::cos(angle), 0, 0,
    0, 0, 1, 0,
    0, 0, 0, 1;
</code></pre>
<figure data-type="image" tabindex="1"><img src="https://i.loli.net/2021/06/08/i46RI9kdg2f8OKH.gif" alt="ZRotate" loading="lazy"></figure>
<h3 id="绕任意轴">绕任意轴</h3>
<pre><code class="language-c++">RotateAxis &lt;&lt; x * x + (1 - x * x) * cos_angle, x *y *(1 - cos_angle) + z *sin_angle, x *z *(1 - cos_angle) - y *sin_angle, 0,
    x *y *(1 - cos_angle) - z *sin_angle, y *y + (1 - y * y) * cos_angle, y *z *(1 - cos_angle) + sin_angle, 0,
    x *z *(1 - cos_angle) + y *sin_angle, y *z *(1 - cos_angle) - x *sin_angle, z *z + (1 - z * z) * cos_angle, 0,
    0, 0, 0, 1;
</code></pre>
<pre><code class="language-C++">Vector3f Vs = { 1,1,1 };
</code></pre>
<figure data-type="image" tabindex="2"><img src="https://i.loli.net/2021/06/08/KOYZfJGtSx75vad.gif" alt="Rotate1" loading="lazy"></figure>
<pre><code class="language-c++">Vector3f Ve = { 0,0,1 };
</code></pre>
<figure data-type="image" tabindex="3"><img src="https://i.loli.net/2021/06/08/7A34hnS8xVzfMce.gif" alt="Rotate2" loading="lazy"></figure>
<h2 id="绕任意轴旋转">绕任意轴旋转</h2>
<pre><code class="language-c++">Eigen::Matrix4f get_model_matrix(Vector3f axis, float angle) {
	Eigen::Matrix4f RotateAxis = Eigen::Matrix4f::Identity();
	float radian = angle / 180 * MY_PI;
	float x = axis.x();
	float y = axis.y();
	float z = axis.z();
	float cos_angle = std::cos(radian);
	float sin_angle = std::sin(radian);

	RotateAxis &lt;&lt; x * x + (1 - x * x)*cos_angle, x*y*(1 - cos_angle) + z * sin_angle, x*z*(1 - cos_angle) - y * sin_angle, 0, \
		x*y*(1 - cos_angle) - z * sin_angle, y*y + (1 - y * y)*cos_angle, y*z*(1 - cos_angle) + sin_angle, 0, \
		x*z*(1 - cos_angle) + y * sin_angle, y*z*(1 - cos_angle) - x * sin_angle, z*z + (1 - z * z)*cos_angle, 0, \
		0, 0, 0, 1;

	return RotateAxis;
}
</code></pre>
<h2 id="其他结果">其他结果</h2>
<h3 id="绕x旋转">绕X旋转</h3>
<pre><code class="language-c++">rotateX &lt;&lt; 1, 0, 0, 0,
    0, std::cos(angle), -std::sin(angle), 0,
    0, std::sin(angle), std::cos(angle), 0,
    0, 0, 0, 1;
</code></pre>
<figure data-type="image" tabindex="4"><img src="https://i.loli.net/2021/06/08/NifPRGlWwjnJd2b.gif" alt="RotateX" loading="lazy"></figure>
<h3 id="绕y旋转">绕Y旋转</h3>
<pre><code class="language-c++">rotateY &lt;&lt; std::cos(angle), 0, std::sin(angle), 0,
    0, 1, 0, 0,
    -std::sin(angle), 0, std::cos(angle), 0,
    0, 0, 0, 1;
</code></pre>
<figure data-type="image" tabindex="5"><img src="https://i.loli.net/2021/06/08/GwD1bHmiSX5QM6q.gif" alt="RotateY" loading="lazy"></figure>
<h3 id="平移-x轴为例">平移 X轴为例</h3>
<pre><code class="language-C++">float step = -angle / 10.0;
translateX &lt;&lt; 1, 0, 0, step,
    0, 1, 0, 0,
    0, 0, 1, 0,
    0, 0, 0, 1;
</code></pre>
<figure data-type="image" tabindex="6"><img src="https://i.loli.net/2021/06/08/hONaZsHByKJzFXk.gif" alt="TransX" loading="lazy"></figure>
<h3 id="缩放">缩放</h3>
<pre><code class="language-c++">//scale with k
float k = .1 * angle; //scale factor
scaleK &lt;&lt; k, 0, 0, 0,
    0, k, 0, 0,
    0, 0, k, 0,
    0, 0, 0, 1;
</code></pre>
<figure data-type="image" tabindex="7"><img src="https://i.loli.net/2021/06/08/cEx8LbiaGXy6HqS.gif" alt="TransX" loading="lazy"></figure>
<p>学生：郝天晨</p>
<p>项目地址 ： <a href="https://github.com/logic-three-body/GameS101_IntroductionTOcomputerGraph/tree/%E4%BD%9C%E4%B8%9A1/Roate_Project">Github</a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Unity技术开放日 北京站]]></title>
        <id>https://logic-three-body.github.io/post/unity-ji-zhu-kai-fang-ri-bei-jing-zhan/</id>
        <link href="https://logic-three-body.github.io/post/unity-ji-zhu-kai-fang-ri-bei-jing-zhan/">
        </link>
        <updated>2021-06-03T04:11:30.000Z</updated>
        <content type="html"><![CDATA[<h1 id="unity技术开放日-北京站">Unity技术开放日 北京站</h1>
<h2 id="前言">前言</h2>
<p>unity官方来北京啦，我也是第一次参加这种官方活动，还比较紧张，但是现场气氛相当活泼，讲师大佬们都非常有趣，非常硬核，感觉和看线上直播还是有很大区别，原来官方的讲师大佬如此亲切，就像朋友聊天一样，感觉非常好！这篇博客先来说几个我印象深刻的吧（随着我的学习，也会对这篇博客的内容更新~）</p>
<p><strong>注：本文图片内容主要来源：</strong><a href="https://unity.cn/ask/question/604884f5edbc2a001f945623">官方ppt</a></p>
<h2 id="hdrp打光实践">HDRP打光实践</h2>
<p>我的第一个unity游戏是和小伙伴利用unity3d默认渲染管线制作的，后来也尝试着把场景导入过urp管线，也在urp管线里制作过VR场景，urp和默认渲染管线里的灯光参数比较简洁，但到了hdrp高清渲染关系里就有非常多和物理相关的参数了,所以就要考虑能量、色温等因素。</p>
<p><strong>HDRP中文版文档</strong>：<a href="https://docs.unity3d.com/cn/Packages/com.unity.render-pipelines.high-definition@10.4/manual/index.html">here</a></p>
<figure data-type="image" tabindex="1"><img src="https://i.loli.net/2021/06/03/7NpCJqxzR6skyUh.png" alt="image-20210603105739224" loading="lazy"></figure>
<figure data-type="image" tabindex="2"><img src="https://i.loli.net/2021/06/03/GhTzmLiR6dyQow2.png" alt="image-20210603105819020" loading="lazy"></figure>
<p>例如：正午的阳光为11到12万Lux</p>
<p>HDRP反射层级：<br>
HDRP 中提供了一个反射层级来为屏幕上的每个像素提供尽量正确的反射信息。在这个反射层级中包含了三种生成反射的方法，HDRP 进行评估的先后次序为：<br>
1.首先评估 <a href="https://www.bilibili.com/video/BV1YK4y1T7yY?p=9"><strong>Screen Space Reflection</strong></a> （屏幕空间反射，简称 SSR）。<br>
2.如果没有找到合适的反射信息， HDRP 会接着评估 Reflection Probe （反射探针） 。<br>
3.如果还是没有得到合适的反射信息，最后会使用来自天空的反射（ Sky reflection ）。</p>
<p>学习hdrp灯光可以从如下框架入手</p>
<figure data-type="image" tabindex="3"><img src="https://i.loli.net/2021/06/03/ZQBdCPi5LnEwaXm.png" alt="image-20210603110042629" loading="lazy"></figure>
<p>物理打光和艺术打光配合：</p>
<p>hdrp教程：<a href="https://www.bilibili.com/video/av672487642">实时光追系列</a> <a href="https://www.bilibili.com/video/BV1gE411T7As?p=28">同济动画Unity美术与技术原理</a></p>
<p>screen space reflect原理: <a href="https://www.bilibili.com/video/BV1YK4y1T7yY?p=9">games202Lec09</a></p>
<p>艺术教程：<a href="https://www.bilibili.com/video/av18001896">贵哥汉化色彩与光线</a> <a href="https://www.bilibili.com/video/av35977423">光影色彩理论</a></p>
<figure data-type="image" tabindex="4"><img src="https://i.loli.net/2021/06/03/Fse7WOkf2lU1oB5.png" alt="image-20210603111704467" loading="lazy"></figure>
<h2 id="低成本水体渲染黎明之海">低成本水体渲染&amp;黎明之海</h2>
<p>低成本水体渲染和的黎明之海的技术分享对我很重要，因为最近想和小伙伴们制作有关海洋环保的主题游戏，所以海面以及海底的渲染是我迫切要学习的。</p>
<p>以前对水体渲染有误区，认为水面和水底是一体的，但其实这是两个完全不同的渲染方式，水面渲染相对难度大，包括利用波函数模拟水体流动，从水上看向水底的折射、反色、焦散等效果，水底一般通过后处理模拟水下模糊场景。</p>
<p>水体模拟解决方案框架：</p>
<figure data-type="image" tabindex="5"><img src="https://i.loli.net/2021/06/03/Euo9I3UJSBDYVMO.png" alt="image-20210603113246492" loading="lazy"></figure>
<figure data-type="image" tabindex="6"><img src="https://i.loli.net/2021/06/03/waY7Sz6mh5nQAcD.png" alt="image-20210603113335476" loading="lazy"></figure>
<p>实时渲染里的水体模拟一般采用波函数模拟动态效果而不采用物理模拟使用的欧拉法或拉格朗日法（因为实在太慢了，伤不起，离线渲染的水和雪的模拟还是让冰雪奇缘类型的电影去用吧）</p>
<p>黎明之海 海洋交互系统：</p>
<figure data-type="image" tabindex="7"><img src="https://i.loli.net/2021/06/03/lcyozZEIMXBJaYv.png" alt="image-20210603114718267" loading="lazy"></figure>
<p>参考：</p>
<p><a href="http://advances.realtimerendering.com/s2019/index.htm">Multi-resolution Ocean Rendering in Crest Ocean System</a></p>
<p><a href="http://advances.realtimerendering.com/s2017/index.html">Crest: Novel Ocean Rendering Techniques in an Open Source Framework</a></p>
<p>对水体模拟的学习，我推荐结合本次技术分享ppt从<a href="https://zhuanlan.zhihu.com/p/95917609">毛星云大佬的文章</a>开始，有一个全局认识，也可以看放牛的星星大佬总结翻译的<a href="https://zhuanlan.zhihu.com/p/196758925">catlikecoding流体模拟系列</a></p>
<h2 id="unity-底层模型之内存">Unity 底层模型之内存</h2>
<p>设计到内存模型的理论确实非常烧脑，不过内存对于正在运行的程序来说非常重要，对内存的优化也是非常复杂的工作</p>
<p>内存是抽象神奇的东西，从物理角度上讲它是一段连续的空间，也就是说在分配内存的时候只看剩余内存大小来分配往往不会获得满意的结果，如果很多小内存片散落在这片内存区域上，即使内存在数值上有很大的剩余也无法再分配一块大的连续内存块了。</p>
<figure data-type="image" tabindex="8"><img src="https://i.loli.net/2021/06/03/rV9fkWlgiYopJND.jpg" alt="" loading="lazy"></figure>
<p>所以一般推荐我们先分配大内存，再分配小内存，避免内存碎片的产生</p>
<p>初学者学习内存我推荐一个超级棒的教程：<a href="https://www.bilibili.com/video/BV1Rb411378V?p=12">CS50</a></p>
<h2 id="后记">后记</h2>
<p>这次活动大开眼界，除了技术干货还有见证了unity背后强大的生态链和业务链，对于引擎背后工具链的熟悉对于开发者也十分重要。</p>
<p>千里之行，始于足下，各位加油！<br>
<img src="https://i.loli.net/2021/06/03/aj6lZKB92rR7Mhd.jpg" alt="" loading="lazy"></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[数字图像处理知识总结]]></title>
        <id>https://logic-three-body.github.io/post/shu-zi-tu-xiang-chu-li-zhi-shi-zong-jie/</id>
        <link href="https://logic-three-body.github.io/post/shu-zi-tu-xiang-chu-li-zhi-shi-zong-jie/">
        </link>
        <updated>2021-05-25T12:25:54.000Z</updated>
        <content type="html"><![CDATA[<h1 id="数字图像处理知识总结">数字图像处理知识总结</h1>
<p>幕布链接：<a href="https://share.mubu.com/doc/5TVGy1QLQvq">here</a></p>
<p>部分内容在<a href="https://share.mubu.com/doc/7p7gHyyHh1q">数字媒体技术基础</a>已经总结</p>
<h2 id="2-数字图像表示及处理">2 数字图像表示及处理</h2>
<h3 id="人眼成像过程">人眼成像过程</h3>
<ul>
<li>
<p>组成</p>
<ul>
<li>
<p>角膜 1/6</p>
</li>
<li>
<p>虹膜 5/6</p>
</li>
<li>
<p>脉络膜</p>
</li>
<li>
<p>瞳孔</p>
<ul>
<li>
<p>虹膜中间</p>
</li>
<li>
<p>光圈</p>
</li>
</ul>
</li>
<li>
<p>视网膜</p>
<ul>
<li>光敏细胞</li>
</ul>
</li>
</ul>
</li>
<li>
<p>过程</p>
<ul>
<li>
<p>图<img src="https://api2.mubu.com/v3/document_image/7DCCAAC01F3146761621750796.jpg" alt="img" loading="lazy"></p>
</li>
<li>
<p>例子<img src="https://api2.mubu.com/v3/document_image/E54E9552ABF0456C1621751033.jpg" alt="img" loading="lazy"></p>
</li>
</ul>
</li>
<li>
<p>人眼机理 照相机</p>
<ul>
<li>
<p>瞳孔 &lt;=&gt; 光圈</p>
</li>
<li>
<p>晶状体 &lt;=&gt; 透镜</p>
</li>
<li>
<p>视细胞</p>
<ul>
<li>
<p>锥状细胞</p>
<ul>
<li>
<p>强光检测亮度、颜色</p>
</li>
<li>
<p>6,000,000～7,000,000</p>
</li>
<li>
<p>对颜色敏感</p>
</li>
<li>
<p>分辨率高</p>
</li>
</ul>
</li>
<li>
<p>杆状细胞</p>
<ul>
<li>
<p>弱光检测亮度，无色彩感觉</p>
</li>
<li>
<p>75,000,000～150,000,000</p>
</li>
<li>
<p>分辨率低</p>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>成像过程</p>
<ul>
<li>
<p>视细胞 受光刺激 产生 电脉冲 -&gt; 视神经中枢-&gt;大脑成像</p>
</li>
<li>
<p>物体 反射/透射 光谱一部分 吸收其余部分 呈现颜色</p>
</li>
<li>
<p>消色光/单色光</p>
<ul>
<li>
<p>无颜色的光</p>
</li>
<li>
<p>灰度</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>色彩感知</p>
<ul>
<li>
<p>度量</p>
<ul>
<li>
<p>亮度</p>
<ul>
<li>明亮</li>
</ul>
</li>
<li>
<p>色调</p>
<ul>
<li>颜色种类</li>
</ul>
</li>
<li>
<p>饱和度</p>
<ul>
<li>深浅</li>
</ul>
</li>
<li>
<p>色度</p>
<ul>
<li>色调和饱和度</li>
</ul>
</li>
</ul>
</li>
<li>
<p>三基色</p>
<ul>
<li>
<p>r g b</p>
</li>
<li>
<p>混色</p>
<ul>
<li>
<p>红绿=黄</p>
</li>
<li>
<p>红蓝=品红</p>
</li>
<li>
<p>绿蓝=青</p>
</li>
<li>
<p>红绿蓝=白</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>例题</p>
<ul>
<li>图<img src="https://api2.mubu.com/v3/document_image/F766AA81BCFB4BD31621752354.jpg" alt="img" loading="lazy"></li>
</ul>
</li>
</ul>
<h3 id="电磁波成像">电磁波成像</h3>
<ul>
<li>
<p>电磁波谱按波长递减</p>
<ul>
<li>gama射线、x射线、紫外线（工业检测、显微镜）、可见光、红外线（车牌识别）、微波（雷达）、无线电波（医学MRI）</li>
</ul>
</li>
<li>
<p>其他成像</p>
<ul>
<li>声波、超声波（B超）、计算机合成图像</li>
</ul>
</li>
<li>
<p>例题</p>
<ul>
<li>图<img src="https://api2.mubu.com/v3/document_image/9980136EAF7C49621621752803.jpg" alt="img" loading="lazy"></li>
</ul>
</li>
</ul>
<h3 id="简单图像形成模型">简单图像形成模型</h3>
<ul>
<li>
<p>图像记录 物体 辐射能量 空间分布</p>
<ul>
<li>
<p>分布 为 空间坐标、波长、时间的函数</p>
</li>
<li>
<p>I=(x,y,z,lamda,t)</p>
<ul>
<li>lamda:波长</li>
</ul>
</li>
</ul>
</li>
<li>
<p>平面单色静止图像</p>
<ul>
<li>
<p>f(x,y)=i(x,y)* r(x,y)</p>
<ul>
<li>
<p>i 入射分量</p>
</li>
<li>
<p>r 反射分量</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="图像获取">图像获取</h3>
<ul>
<li>
<p>采集部件</p>
<ul>
<li>
<p>光敏器件</p>
</li>
<li>
<p>扫描系统</p>
</li>
<li>
<p>模/数转换</p>
</li>
</ul>
</li>
<li>
<p>输入设备</p>
<ul>
<li>
<p>CCD光电器件</p>
<ul>
<li>
<p>摄像机</p>
</li>
<li>
<p>数字相机</p>
</li>
<li>
<p>平板扫描仪</p>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>输出设备</p>
<ul>
<li>滚筒扫描仪</li>
</ul>
</li>
<li>
<p>例题</p>
<ul>
<li>打印机不属于采集设备</li>
</ul>
</li>
</ul>
<h3 id="图像数字化">图像数字化</h3>
<h4 id="步骤">步骤</h4>
<ul>
<li>
<p>扫描</p>
<ul>
<li>按顺序对图像遍历</li>
</ul>
</li>
<li>
<p>采样</p>
<ul>
<li>用光电传感器对像素位置上的像素取值</li>
</ul>
</li>
<li>
<p>量化</p>
<ul>
<li>对采样值模数转换</li>
</ul>
</li>
</ul>
<h4 id="设备">设备</h4>
<ul>
<li>
<p>采样孔</p>
<ul>
<li>单独观测特定图像像素 不受图像其他部分影响</li>
</ul>
</li>
<li>
<p>图像扫描机构</p>
<ul>
<li>让 采样孔 按照 预先规定的方式在图像移动 ，按顺序观测每一个像素</li>
</ul>
</li>
<li>
<p>光传感器</p>
<ul>
<li>通过采样孔测量图像 每像素亮度
<ul>
<li>通常 为 光强 转换为 电压或电流变换器</li>
</ul>
</li>
</ul>
</li>
<li>
<p>量化器</p>
<ul>
<li>将传感器输出的连续量 转化为 整数值</li>
</ul>
</li>
<li>
<p>输出存储体</p>
<ul>
<li>把量化器产生的灰度值按某格式存储</li>
</ul>
</li>
</ul>
<h4 id="性能">性能</h4>
<ul>
<li>
<p>空间分辨率 采样决定</p>
<ul>
<li>
<p>单位尺寸采样像素数</p>
</li>
<li>
<p>采样孔径与间距大小和可变范围决定</p>
</li>
</ul>
</li>
<li>
<p>灰度分辨率 量化决定</p>
<ul>
<li>量化等级（位深度） 颜色深度</li>
</ul>
</li>
<li>
<p>图像大小</p>
<ul>
<li>扫描最大幅度</li>
</ul>
</li>
<li>
<p>量测特征</p>
<ul>
<li>测量的精度</li>
</ul>
</li>
<li>
<p>扫描速度</p>
<ul>
<li>采样数据传输速度</li>
</ul>
</li>
<li>
<p>噪声 量化噪声/误差</p>
<ul>
<li>数字化器噪声水平</li>
</ul>
</li>
<li>
<p>其他</p>
<ul>
<li>价格</li>
</ul>
</li>
</ul>
<h4 id="采样-量化依据">采样 量化依据</h4>
<ul>
<li>二维采样定理 Nyquist准则</li>
</ul>
<h4 id="采样点-量化级数-数字媒体技术期末复习总结">采样点 量化级数 <a href="https://share.mubu.com/doc/7p7gHyyHh1q">数字媒体技术期末复习总结</a></h4>
<ul>
<li>越高越好</li>
</ul>
<h4 id="像素关系">像素关系</h4>
<ul>
<li>
<p>4邻域</p>
</li>
<li>
<p>图<img src="https://api2.mubu.com/v3/document_image/94905986238044361621755609.jpg" alt="img" loading="lazy"></p>
</li>
<li>
<p>4对角邻域</p>
</li>
<li>
<p>图<img src="https://api2.mubu.com/v3/document_image/30B819FE9872405E1621755618.jpg" alt="img" loading="lazy"></p>
</li>
<li>
<p>8邻域</p>
</li>
<li>
<p>图<img src="https://api2.mubu.com/v3/document_image/E2665FB120764D9D1621755628.jpg" alt="img" loading="lazy"></p>
</li>
<li>
<p>邻接性</p>
<ul>
<li>
<p>V：灰度值集合</p>
<ul>
<li>如二值图像 V={1}</li>
</ul>
</li>
<li>
<p>如果q在N(p)中，具有V中数值两数为邻接</p>
</li>
<li>
<p>4邻接</p>
</li>
<li>
<p>8邻接</p>
</li>
<li>
<p>m邻接/混合邻接</p>
</li>
</ul>
</li>
<li>
<p>连通性</p>
</li>
<li>
<p>从p到q有特定像素序列</p>
</li>
<li>
<p>区域</p>
</li>
<li>
<p>连通区</p>
</li>
<li>
<p>边界 边缘</p>
<ul>
<li>
<p>边界</p>
<ul>
<li>
<p>闭合通路</p>
</li>
<li>
<p>整体</p>
</li>
</ul>
</li>
<li>
<p>边缘</p>
<ul>
<li>
<p>某些导数值（超过预先设定阈值）像素形成</p>
</li>
<li>
<p>局部</p>
<ul>
<li>灰度级测量不连续</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>放大/收缩图像</p>
<ul>
<li>
<p>放大</p>
<ul>
<li>
<p>创立新像素位置</p>
</li>
<li>
<p>赋予像素值</p>
</li>
</ul>
</li>
<li>
<p>缩小</p>
<ul>
<li>删除行列</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="距离度量-数字媒体技术期末复习总结">距离度量 <a href="https://share.mubu.com/doc/7p7gHyyHh1q">数字媒体技术期末复习总结</a></h4>
<h4 id="图像格式">图像格式</h4>
<ul>
<li>
<p>bmp</p>
</li>
<li>
<p>tiff</p>
</li>
<li>
<p>gif</p>
</li>
<li>
<p>pcx</p>
</li>
<li>
<p>jpeg</p>
<ul>
<li>joint photographer’s experts group</li>
</ul>
</li>
</ul>
<h4 id="灰度直方图-数字媒体技术期末复习总结">灰度直方图 <a href="https://share.mubu.com/doc/7p7gHyyHh1q">数字媒体技术期末复习总结</a></h4>
<ul>
<li>
<p>例题</p>
<ul>
<li>图<img src="https://api2.mubu.com/v3/document_image/595124E78FBF4F7E1621756598.jpg" alt="img" loading="lazy"></li>
</ul>
</li>
</ul>
<h2 id="3-vc-图像处理">3 vc++ 图像处理</h2>
<h3 id="bmp">bmp</h3>
<h4 id="特点">特点</h4>
<ul>
<li>
<p>格式：与硬件设备无关</p>
</li>
<li>
<p>难压缩，占用空间大</p>
</li>
<li>
<p>深度:1bits,4bits,8bits,24bits</p>
</li>
</ul>
<h4 id="扫描方式">扫描方式</h4>
<ul>
<li>从左到右，从下到上</li>
</ul>
<h4 id="图像-框架">图像 框架</h4>
<ul>
<li>如图<img src="https://api2.mubu.com/v3/document_image/BE4AB55919A047D51621742033.jpg" alt="img" loading="lazy"></li>
</ul>
<h5 id="文件头">文件头</h5>
<ul>
<li>
<p>bfType：位图文件类型 0x424D 字符串“BM”</p>
</li>
<li>
<p>bfSize：位图文件大小 包括这14个Byte</p>
</li>
<li>
<p>bfReserved1，bfReserved2:Windows保留字</p>
</li>
<li>
<p>bfOffBits：文件头到实际位图数据偏移字节数</p>
</li>
</ul>
<h5 id="信息头">信息头</h5>
<ul>
<li>
<p>biSize：本结构长度 40Bytes</p>
</li>
<li>
<p>biWidth：位图宽度 pixel</p>
</li>
<li>
<p>biHeight：位图高度 pixel</p>
</li>
<li>
<p>biPlanes：目标设备级别 1</p>
</li>
<li>
<p>biBitCount：每像素所占位数bit</p>
</li>
<li>
<p>biCompression：位图压缩类型</p>
<ul>
<li>例如BI_RGB</li>
</ul>
</li>
<li>
<p>biSizeImage：实际位图数据占用字节数</p>
</li>
<li>
<p>biXPelsPerMeter:目标设备水平分辨率 像素/米</p>
</li>
<li>
<p>biYPelsPerMeter：目标设备垂直分辨率 像素/米</p>
</li>
<li>
<p>biClrUsed：位图实际用到的颜色数</p>
<ul>
<li>若为0，则颜色数=2^biBitCount<br>
- 例如rgb图像</li>
</ul>
</li>
<li>
<p>biClrImportant：位图显示过程重要颜色数</p>
<ul>
<li>若为0则全重要</li>
</ul>
</li>
</ul>
<h5 id="颜色表调色板">颜色表/调色板</h5>
<ul>
<li>
<p>颜色表是RGBQUAD数组</p>
<ul>
<li>图<img src="https://api2.mubu.com/v3/document_image/30C4BA5992C24AFA1621747955.jpg" alt="img" loading="lazy"></li>
</ul>
</li>
</ul>
<h5 id="位图数据">位图数据</h5>
<ul>
<li>
<p>记录每一个像素值R G B （存储顺序为B G R）</p>
</li>
<li>
<p>若有颜色表，则位图数据为调色板索引值</p>
</li>
<li>
<p>注意</p>
<ul>
<li>
<p>（Windows）扫描行 所占字节数 为 4 的倍数 ，不足的要扩充</p>
<ul>
<li>
<p>DataSizePerLine=int[(biWidth*biBitCount/8+3)/4]*4</p>
</li>
<li>
<p>不压缩位图数据大小</p>
</li>
<li>
<p>biSizeImage=DataSizePerLine*biHeight</p>
<ul>
<li>扫描顺序：下到上，左到右，图像坐标零点在左下角</li>
</ul>
</li>
</ul>
</li>
<li>
<h2 id="例题">例题<img src="https://api2.mubu.com/v3/document_image/F176741904BA4DFB1621749705.jpg" alt="img" loading="lazy"></h2>
</li>
</ul>
</li>
</ul>
<h2 id="4-图像变换与运算">4 图像变换与运算</h2>
<h3 id="傅立叶变换">傅立叶变换</h3>
<h4 id="一维傅立叶变换">一维傅立叶变换</h4>
<h4 id="二维傅立叶变换">二维傅立叶变换</h4>
<ul>
<li>
<p>性质</p>
<ul>
<li>
<p>分离性</p>
</li>
<li>
<p>平移性</p>
</li>
<li>
<p>周期性和共轭对称性</p>
</li>
<li>
<p>旋转性</p>
</li>
<li>
<p>分配律</p>
<ul>
<li>乘法不满足</li>
</ul>
</li>
<li>
<p>尺度变换</p>
</li>
<li>
<p>平均值</p>
<ul>
<li>原点值和函数平均值成正比</li>
</ul>
</li>
<li>
<p>卷积</p>
</li>
<li>
<p>相关</p>
</li>
</ul>
</li>
</ul>
<h4 id="快速傅立叶变换-fft">快速傅立叶变换 fft</h4>
<h4 id="傅立叶逆变换">傅立叶逆变换</h4>
<h4 id="可分离变换">可分离变换</h4>
<ul>
<li>
<p>g(x,y,u,v)=g1(x,u)g2(y,v)</p>
</li>
<li>
<p>傅立叶变换是可分离变换的特例</p>
</li>
</ul>
<h4 id="图像运算">图像运算</h4>
<h5 id="点运算见第五章">点运算（见第五章）</h5>
<h5 id="局域运算见第五章">局域运算（见第五章）</h5>
<h5 id="代数运算">代数运算</h5>
<ul>
<li>
<p>加减乘除</p>
</li>
<li>
<p>用途</p>
<ul>
<li>
<p>加</p>
<ul>
<li>均值降噪
<ul>
<li>多幅图像求均值</li>
</ul>
</li>
</ul>
</li>
<li>
<p>减</p>
<ul>
<li>
<p>减去背景</p>
</li>
<li>
<p>运动检测</p>
</li>
<li>
<p>梯度幅度</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h5 id="几何运算">几何运算</h5>
<h6 id="概念">概念</h6>
<ul>
<li>改变空间关系</li>
</ul>
<h6 id="空间变换">空间变换</h6>
<ul>
<li>
<p>像素位置移动</p>
</li>
<li>
<p>变换后保证 曲线连续性 物体连通性</p>
</li>
<li>
<p>g(x,y)=f[a(x,y),b(x,y) ]</p>
<ul>
<li>a，b唯一描述 空间变换</li>
</ul>
</li>
</ul>
<h6 id="灰度级插值">灰度级插值</h6>
<ul>
<li>
<p>输入坐标值为整数 运算输出可能不为整数</p>
</li>
<li>
<p>g(x,y)=f[a(x,y),b(x,y) ]</p>
<ul>
<li>f(x,y) 一个像素 往往 被映射到g(x,y)几个位置</li>
</ul>
</li>
<li>
<p>向前映射 移交映射 pixel carry over</p>
<ul>
<li>
<p>输入 img 像素 -&gt; 输出，若一个像素 映射到 四个 输出像素间 则 插值</p>
</li>
<li>
<p>映射输出图像外 浪费</p>
</li>
</ul>
</li>
<li>
<p>向后映射 像素填充 pixel filling</p>
<ul>
<li>
<p>输出 img 像素 -&gt;输入，若一个像素 映射到 四个 输入像素间 则插值</p>
</li>
<li>
<p>逐像素、逐行生成 输出 img</p>
</li>
</ul>
</li>
<li>
<p>插值</p>
<ul>
<li>
<p>最近邻（零阶）</p>
<ul>
<li>输出灰度值等于离他映射最近灰度</li>
</ul>
</li>
<li>
<p>双线性</p>
</li>
<li>
<p>高阶</p>
</li>
</ul>
</li>
</ul>
<h6 id="变换">变换</h6>
<ul>
<li>
<p>平移</p>
</li>
<li>
<p>图<img src="https://api2.mubu.com/v3/document_image/5E0C561CCAD842011621741278.jpg" alt="img" loading="lazy"></p>
</li>
<li>
<p>缩放</p>
</li>
<li>
<p>图<img src="https://api2.mubu.com/v3/document_image/32AF0DA5A1F64BB91621741287.jpg" alt="img" loading="lazy"></p>
</li>
<li>
<p>旋转</p>
<ul>
<li>图<img src="https://api2.mubu.com/v3/document_image/B5108C70034C4F631621741293.jpg" alt="img" loading="lazy"></li>
</ul>
</li>
</ul>
<h2 id="5-图像增强">5 图像增强</h2>
<h3 id="概述">概述</h3>
<ul>
<li>
<p>突出 图像 有用信息 削弱 无用信息</p>
<ul>
<li>
<p>目的</p>
<ul>
<li>便于 后续 人工/机器 观察 分析</li>
</ul>
</li>
<li>
<p>图像信息 有损</p>
</li>
<li>
<p>预处理</p>
</li>
</ul>
<p>空域增强</p>
<ul>
<li>
<p>二维空间 对 图像像素 灰度值 处理</p>
</li>
<li>
<p>灰度变换</p>
<ul>
<li>
<p>像素 灰度值 -数学公式 -&gt; 新灰度值</p>
<ul>
<li>点运算</li>
</ul>
</li>
<li>
<p>对比度增强 直方图均衡</p>
</li>
</ul>
</li>
<li>
<p>空间滤波</p>
<ul>
<li>
<p>邻域处理 局域运算</p>
</li>
<li>
<p>模版 对 像素 周围邻域像素 -数学运算-&gt; 新灰度值</p>
</li>
<li>
<p>图像平滑 锐化</p>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>频域增强</p>
<ul>
<li>
<p>对 图像 傅立叶变换</p>
</li>
<li>
<p>空间域 -&gt; 频率域</p>
</li>
<li>
<p>对频谱 操作</p>
</li>
<li>
<p>反变换回 空间域</p>
</li>
</ul>
</li>
<li>
<p>按对象区分</p>
<ul>
<li>
<p>灰度图增强</p>
</li>
<li>
<p>彩色图增强</p>
</li>
</ul>
</li>
</ul>
<h3 id="空域增强">空域增强</h3>
<h4 id="灰度变换增强">灰度变换增强</h4>
<ul>
<li>
<p>点运算</p>
</li>
<li>
<p>对比度增强</p>
</li>
<li>
<p>线性灰度变换</p>
<ul>
<li>
<p>g(x,y)=a*f(x,y)+b</p>
<ul>
<li>
<p>a=1,b=0 不变</p>
</li>
<li>
<p>a=1,b!=0 上/下移 亮/暗</p>
</li>
<li>
<p>a&gt;1 对比度增强</p>
</li>
<li>
<p>0&lt;a&lt;1 对比度减小</p>
</li>
<li>
<p>a&lt;0 亮区暗 暗区亮 求补</p>
</li>
<li>
<p>图</p>
<ul>
<li>如图<img src="https://api2.mubu.com/v3/document_image/0838F3BAF86A462D1621660557.jpg" alt="img" loading="lazy"></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>分段线性变换</p>
<ul>
<li>
<p>局部拉伸</p>
</li>
<li>
<p>不同范围灰度值进行不同拉伸处理</p>
</li>
<li>
<p>图</p>
<ul>
<li>如图<img src="https://api2.mubu.com/v3/document_image/7C2086A18ACD4E631621660697.jpg" alt="img" loading="lazy"></li>
</ul>
</li>
</ul>
</li>
<li>
<p>非线性变换</p>
<ul>
<li>
<p>在整个灰度范围内 利用非线性变换函数 对灰度范围 扩展/压缩</p>
</li>
<li>
<p>对数扩展</p>
<ul>
<li>g(x,y)=C*ln[f(x,y)+1]
<ul>
<li>如图<img src="https://api2.mubu.com/v3/document_image/172D9D5162954F381621660930.jpg" alt="img" loading="lazy"></li>
</ul>
</li>
</ul>
</li>
<li>
<p>指数扩展</p>
<ul>
<li>
<p>g(x,y)=(a^c*[f(x,y)-b])-1</p>
</li>
<li>
<p>b可改变曲线起始位置</p>
</li>
<li>
<p>c可改变曲线变化速率</p>
</li>
<li>
<p>可对高亮度区进行大幅扩展</p>
</li>
</ul>
</li>
<li>
<p>伽马变换</p>
<ul>
<li>
<p>g(x,y)=(f(x,y)+esp)^r</p>
<ul>
<li>
<p>f,g 范围 [0,1]</p>
</li>
<li>
<p>esp 补偿系数</p>
</li>
<li>
<p>r 伽马系数</p>
<ul>
<li>可选择性 增强 低灰度区域对比度 或 高灰度区对比度<img src="https://api2.mubu.com/v3/document_image/DBD2F055A78A471D1621661392.jpg" alt="img" loading="lazy"></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>其他</p>
<ul>
<li>
<p>求反</p>
</li>
<li>
<p>动态范围压缩</p>
</li>
<li>
<p>阶梯量化</p>
</li>
<li>
<p>阈值切分</p>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>课堂练习（提问）</p>
<ul>
<li>
<p>不在范围内的灰度值怎么办？</p>
</li>
<li>
<p>解<img src="https://api2.mubu.com/v3/document_image/81569A45A14043C21621661663.jpg" alt="img" loading="lazy"></p>
</li>
</ul>
</li>
</ul>
<h4 id="直方图增强">直方图增强</h4>
<ul>
<li>
<p>p(r)=n(r)</p>
<ul>
<li>
<p>n(r) 灰度为r 像素数</p>
</li>
<li>
<p>p(r)=n(r)/N</p>
<ul>
<li>N:总像素数</li>
</ul>
</li>
</ul>
</li>
<li>
<p>直方图均衡化 <a href="https://mubu.com/doc50rcPGgAYM0">数字媒体技术期末复习总结</a></p>
<ul>
<li>
<p>搜索均衡化</p>
</li>
<li>
<p>⚠️注意 图像处理专业课的均衡化需要看以下举例</p>
</li>
<li>
<p>举例</p>
<ul>
<li>如图<img src="https://api2.mubu.com/v3/document_image/1A0F78200C654F8B1621662815.jpg" alt="img" loading="lazy"><img src="https://api2.mubu.com/v3/document_image/F4C937A6516E4FAD1621662815.jpg" alt="img" loading="lazy"><img src="https://api2.mubu.com/v3/document_image/825D6646699F4EE51621662815.jpg" alt="img" loading="lazy"></li>
</ul>
</li>
<li>
<p>简化公式</p>
<ul>
<li>图<img src="https://api2.mubu.com/v3/document_image/81E3B5737C99427D1621662898.jpg" alt="img" loading="lazy"></li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="平滑-空间滤波">平滑 空间滤波</h4>
<ul>
<li>
<p>邻域平均 线性</p>
<ul>
<li>
<p>均值滤波（局部平滑）</p>
<ul>
<li>
<p>去除不相干细节</p>
</li>
<li>
<p>图<img src="https://api2.mubu.com/v3/document_image/9CE274A0E0B9422A1621663892.jpg" alt="img" loading="lazy"></p>
</li>
</ul>
</li>
<li>
<p>高斯滤波 加权平均</p>
<ul>
<li>图<img src="https://api2.mubu.com/v3/document_image/16C224911C284EB91621663882.jpg" alt="img" loading="lazy"></li>
</ul>
</li>
</ul>
</li>
<li>
<p>中值滤波 非线性</p>
<ul>
<li>
<p>步骤</p>
<ul>
<li>
<p>确定奇数像素窗口W</p>
</li>
<li>
<p>窗口内 像素 按灰度值从小到大排序</p>
</li>
<li>
<p>中间像素代替灰度值</p>
</li>
</ul>
</li>
<li>
<p>去除孤立像素</p>
<ul>
<li>即 相对邻近像素过亮/暗</li>
</ul>
</li>
<li>
<p>除了中值代替，也可以最大值最小值</p>
</li>
</ul>
</li>
<li>
<p>平滑-&gt;减噪</p>
<ul>
<li>负面效应 边缘模糊</li>
</ul>
</li>
<li>
<p>举例</p>
<ul>
<li>图<img src="https://api2.mubu.com/v3/document_image/23A5AB2099DF43FF1621664206.jpg" alt="img" loading="lazy"><img src="https://api2.mubu.com/v3/document_image/1AB2C88A1A004F501621664206.jpg" alt="img" loading="lazy"></li>
</ul>
</li>
</ul>
<h4 id="锐化">锐化</h4>
<ul>
<li>
<p>增强反差 边缘信息 便于轮廓提取</p>
<ul>
<li>边缘 轮廓 是变化最大处</li>
</ul>
</li>
<li>
<p>微分</p>
<ul>
<li>
<p>增强边缘</p>
</li>
<li>
<p>削弱变化缓慢区</p>
</li>
<li>
<p>边缘检测</p>
</li>
</ul>
</li>
<li>
<p>差分代替微分</p>
<ul>
<li>
<p>公式</p>
<ul>
<li>图<img src="https://api2.mubu.com/v3/document_image/803106F22271471A1621664544.jpg" alt="img" loading="lazy"></li>
</ul>
</li>
<li>
<p>举例</p>
<ul>
<li>
<p>图<img src="https://api2.mubu.com/v3/document_image/13EA8137591842B41621664730.jpg" alt="img" loading="lazy"></p>
</li>
<li>
<p>分析</p>
<ul>
<li>
<p>整个斜坡 一阶微分不为0 二阶微分 非0值只在斜坡起始处 终点处</p>
<ul>
<li>
<p>一阶微分 较粗边缘</p>
</li>
<li>
<p>二阶微分 较细边缘</p>
</li>
</ul>
</li>
<li>
<p>噪点处 二阶比一阶反应强烈</p>
<ul>
<li>
<p>细节增强 ，二阶优于一阶</p>
</li>
<li>
<p>二阶有过渡（正回到负） ，双线 现象</p>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>结论</p>
<ul>
<li>
<p>一阶 产生宽边缘</p>
</li>
<li>
<p>二阶 细节 反应强</p>
</li>
<li>
<p>一阶 灰度阶梯 反应强</p>
</li>
<li>
<p>二阶                       双响应</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>一阶微分 梯度算子</p>
<ul>
<li>
<p>roberts</p>
<ul>
<li>图<img src="https://api2.mubu.com/v3/document_image/7109842A84B24F7A1621665516.jpg" alt="img" loading="lazy"></li>
</ul>
</li>
<li>
<p>sobel</p>
<ul>
<li>
<p>图<img src="https://api2.mubu.com/v3/document_image/F783BC08D82041F01621665525.jpg" alt="img" loading="lazy"></p>
</li>
<li>
<p>sx对水平边缘 响应大</p>
</li>
<li>
<p>sy 垂直</p>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>二阶微分 拉普拉斯算子</p>
<ul>
<li>图<img src="https://api2.mubu.com/v3/document_image/A5749E1E719749081621665563.jpg" alt="img" loading="lazy"></li>
</ul>
</li>
<li>
<p>注意</p>
<ul>
<li>
<p>锐化计算后得到梯度值G[f(x,y)]</p>
</li>
<li>
<p>可设定阈值 T</p>
<ul>
<li>
<p>g(x,y)=G[f(x,y)],G[f(x,y)]&gt;=T</p>
</li>
<li>
<p>g(x,y)=f(x,y) ,G[f(x,y)]&lt;T</p>
</li>
</ul>
</li>
<li>
<p>频域增强</p>
<ul>
<li>
<p>步骤</p>
<ul>
<li>
<p>原图 f(x,y) 傅立叶变换 F(u,v)</p>
</li>
<li>
<p>F(u,v)*H(u,v) 传递函数 -&gt; G(u,v)</p>
</li>
<li>
<p>G(u,v) 傅立叶逆变换 g(x,y)</p>
</li>
</ul>
</li>
<li>
<p>空间域-&gt;变换域</p>
<ul>
<li>
<p>低频分量 图像灰度值变化缓慢</p>
</li>
<li>
<p>高频           边缘 随机噪声</p>
</li>
</ul>
</li>
<li>
<p>低通滤波</p>
<ul>
<li>
<p>保留低频 过滤高频</p>
</li>
<li>
<p>种类</p>
<ul>
<li>
<p>理想低通滤波ILPF</p>
</li>
<li>
<p>巴特沃斯</p>
</li>
<li>
<p>指数</p>
</li>
<li>
<p>梯形</p>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>高通滤波</p>
<ul>
<li>
<p>理想</p>
<ul>
<li>振铃明显 图像边缘模糊</li>
</ul>
</li>
<li>
<p>巴特沃斯</p>
<ul>
<li>效果好 振铃不明显 计算复杂</li>
</ul>
</li>
<li>
<p>指数</p>
<ul>
<li>稍逊于巴特沃斯</li>
</ul>
</li>
<li>
<p>梯形</p>
<ul>
<li>微有振铃 计算简单 常用</li>
</ul>
</li>
</ul>
</li>
<li>
<p>带阻滤波</p>
<ul>
<li>允许 阻止 特定频段通过 传递函数</li>
</ul>
</li>
<li>
<p>同态滤波</p>
<ul>
<li>
<p>压缩图像范围 增强对比度</p>
</li>
<li>
<p>分离 照明分量 反射分量</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="彩色图像增强">彩色图像增强</h3>
<ul>
<li>
<p>增强技术</p>
<ul>
<li>
<p>真彩色</p>
</li>
<li>
<p>假彩色</p>
</li>
<li>
<p>伪彩色</p>
</li>
</ul>
</li>
<li>
<p>彩色模型 <a href="https://share.mubu.com/doc/7p7gHyyHh1q">数字媒体技术期末复习总结</a></p>
<ul>
<li>
<p>rgb</p>
</li>
<li>
<p>hsi</p>
</li>
<li>
<p>cmy</p>
</li>
</ul>
</li>
<li>
<p>伪彩色增强</p>
<ul>
<li>灰度-&gt;彩色</li>
</ul>
</li>
<li>
<p>假彩色增强</p>
<ul>
<li>
<p>彩色-&gt;彩色</p>
</li>
<li>
<p>rgb 映射 rgb</p>
</li>
</ul>
</li>
<li>
<p>真彩色增强</p>
<ul>
<li>图<img src="https://api2.mubu.com/v3/document_image/6EB50F4A7B5744E31621695345.jpg" alt="img" loading="lazy"></li>
</ul>
</li>
</ul>
<h2 id="7-二值图像-形态学">7  二值图像 形态学</h2>
<h3 id="二值图">二值图</h3>
<h4 id="阈值选择">阈值选择</h4>
<ul>
<li>
<p>直方图</p>
<ul>
<li>
<p>对象图形与背景灰度值差很大 ，直方图形成谷</p>
</li>
<li>
<p>干扰多图像不适应</p>
</li>
</ul>
</li>
</ul>
<h4 id="像素连接">像素连接</h4>
<ul>
<li>
<p>连接成分</p>
<ul>
<li>图<img src="https://api2.mubu.com/v3/document_image/0200DD01F03843CC1621868593.jpg" alt="img" loading="lazy"></li>
</ul>
</li>
<li>
<p>孔</p>
<ul>
<li>图<img src="https://api2.mubu.com/v3/document_image/0B3F1094572644A11621868685.jpg" alt="img" loading="lazy"></li>
</ul>
</li>
<li>
<p>单连接成分、多重连接成分</p>
<ul>
<li>图<img src="https://api2.mubu.com/v3/document_image/5FEB2C79700D40F41621869091.jpg" alt="img" loading="lazy"></li>
</ul>
</li>
<li>
<p>图像连接数例题</p>
<ul>
<li>图<img src="https://api2.mubu.com/v3/document_image/304FD6BBC47947051621868374.jpg" alt="img" loading="lazy"></li>
</ul>
</li>
<li>
<p>可删除性</p>
<ul>
<li>
<p>改变一个像素值，整个图像连通性不变</p>
</li>
<li>
<p>可删除像素和连接数等于1的像素一致</p>
</li>
</ul>
</li>
</ul>
<h3 id="形态学">形态学</h3>
<h4 id="基本思想">基本思想</h4>
<ul>
<li>
<p>一定 形态结构元素 度量提取 图像 以便 图像分析</p>
</li>
<li>
<p>集合论</p>
</li>
<li>
<p>保持图像基本结构 除去不想干结构</p>
</li>
</ul>
<h4 id="腐蚀">腐蚀</h4>
<ul>
<li>
<p>步骤</p>
<ul>
<li>
<p>结构元素与覆盖图像</p>
</li>
<li>
<p>如果结果均为1，则为1，否则为0</p>
</li>
</ul>
</li>
<li>
<p>消除边界点/小点</p>
</li>
</ul>
<h4 id="膨胀">膨胀</h4>
<ul>
<li>
<p>步骤</p>
<ul>
<li>
<p>结构元素与覆盖图像</p>
</li>
<li>
<p>如果结果均为0，则为0，否则为1</p>
</li>
</ul>
</li>
<li>
<p>填补空洞</p>
</li>
</ul>
<h4 id="开">开</h4>
<ul>
<li>
<p>腐蚀 膨胀</p>
</li>
<li>
<p>消除小物体</p>
</li>
<li>
<p>平滑对象轮廓</p>
</li>
</ul>
<h4 id="闭">闭</h4>
<ul>
<li>
<p>膨胀 腐蚀</p>
</li>
<li>
<p>填补空洞</p>
</li>
<li>
<p>平滑边界</p>
</li>
</ul>
<h4 id="例题-2">例题</h4>
<ul>
<li>图<img src="https://api2.mubu.com/v3/document_image/718EE5018AC145221621870163.jpg" alt="img" loading="lazy"></li>
</ul>
<h2 id="8-图像压缩">8 图像压缩</h2>
<p>例题</p>
<ul>
<li>图<img src="https://api2.mubu.com/v3/document_image/427ADBB8EA5246321621871644.jpg" alt="img" loading="lazy"><img src="https://api2.mubu.com/v3/document_image/F9F1743BA679471C1621871644.jpg" alt="img" loading="lazy"><img src="https://api2.mubu.com/v3/document_image/42A5D83A2FC1418A1621871644.jpg" alt="img" loading="lazy"><img src="https://api2.mubu.com/v3/document_image/75B23AEBD1BA440B1621871644.jpg" alt="img" loading="lazy"><img src="https://api2.mubu.com/v3/document_image/B7216034778949511621871644.jpg" alt="img" loading="lazy"></li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[THREE.JS shader 实现Phong光照模型]]></title>
        <id>https://logic-three-body.github.io/post/threejs-shader-shi-xian-phong-guang-zhao-mo-xing/</id>
        <link href="https://logic-three-body.github.io/post/threejs-shader-shi-xian-phong-guang-zhao-mo-xing/">
        </link>
        <updated>2021-05-19T13:46:24.000Z</updated>
        <content type="html"><![CDATA[<h2 id="前言">前言</h2>
<p>本次实验利用three.js实现phong材质【之前在GAMES202<a href="https://github.com/logic-three-body/GAMES202_HQRTR/tree/master/homework0/src/shaders/phongShader">作业0</a>里也接触过phong shader的glsl版本】，算法部分不难理解，本次遇到的困难主要在于不熟悉three.js的shader接口【就像unity shaderlab里会有一些专门的变量供用户调用用于顶点、法线等计算】，之后会分析three.js的<a href="http://www.yanhuangxueyuan.com/threejs/docs/index.html#api/zh/materials/ShaderMaterial">ShaderMaterial</a>的坑。</p>
<p>项目工程：<a href="https://github.com/logic-three-body/ThreeJSLearn/tree/master/%E5%AE%9E%E9%AA%8C7/shader/earth">here</a></p>
<h2 id="结果图">结果图</h2>
<figure data-type="image" tabindex="1"><img src="https://logic-three-body.github.io//post-images/1621432131314.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="2"><img src="https://logic-three-body.github.io//post-images/1621432189762.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="3"><img src="https://logic-three-body.github.io//post-images/1621432198510.png" alt="" loading="lazy"></figure>
<h2 id="代码">代码</h2>
<h3 id="uniform">uniform</h3>
<pre><code class="language-javascript">    var uniforms;
    uniforms = {
      uSampler: {//采样的图片
        value: texture,
      },
      uTextureSample: {//采样选择 1为贴图 2为不带贴图
        value: 1
      },
      uKd: {
        value: new THREE.Vector3(0.05, 0.05, 0.05)//控制满反射系数
      },
      uKs: {
        value: new THREE.Vector3(0.5, 0.5, 0.5)//控制高光系数
      },
      lightPosition: {//光源位置
        value: point.position
      },
      uLightIntensity: {
        value: 1155.0//光照强度
      }
    };
    var material_raw = new THREE.ShaderMaterial({
      uniforms: uniforms,
      vertexShader: document.getElementById('vertexShader').textContent,
      fragmentShader: document.getElementById('fragmentShader').textContent,
    });
</code></pre>
<h3 id="顶点着色器">顶点着色器</h3>
<pre><code class="language-javascript">  &lt;script id=&quot;vertexShader&quot; type=&quot;x-shader/x-vertex&quot;&gt;
    attribute vec3 aNormalPosition;
    attribute vec2 aTextureCoord;
    varying highp vec2 vTextureCoord;
    varying highp vec3 vFragPos;
    varying highp vec3 vNormal;
    /*
    normal,position以及摄像机位置需要使用three.js内置参数
    */
    
    void main(void) {
    
      vFragPos = position;
      vNormal = normal;
      gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);  
      vTextureCoord = uv;
    
    }    
&lt;/script&gt;
</code></pre>
<h3 id="片元着色器">片元着色器</h3>
<pre><code class="language-javascript">  &lt;script id=&quot;fragmentShader&quot; type=&quot;x-shader/x-fragment&quot;&gt;
    #ifdef GL_ES
    precision mediump float;  
    #endif
    uniform sampler2D uSampler;
    uniform vec3 uKd;
    uniform vec3 uKs;
    uniform vec3 lightPosition;
    uniform float uLightIntensity;
    uniform int uTextureSample;
    
    varying highp vec2 vTextureCoord;
    varying highp vec3 vFragPos;
    varying highp vec3 vNormal;
    
    void main(void) {
      vec3 color;
      if (uTextureSample == 1) {
        color = pow(texture2D(uSampler, vTextureCoord).rgb, vec3(2.2));
      } else {
        color = uKd;
      }


      vec3 ambient = 0.05 * color;
    
      vec3 lightDir = normalize(lightPosition - vFragPos);
      vec3 normal = normalize(vNormal);
      float diff = max(dot(lightDir, normal), 0.0);
      float light_atten_coff = uLightIntensity / length(lightPosition - vFragPos);
      vec3 diffuse =  diff * light_atten_coff * color;
    
      vec3 viewDir = normalize(cameraPosition - vFragPos);
      float spec = 0.0;
      vec3 reflectDir = reflect(-lightDir, normal);
      spec = pow (max(dot(viewDir, reflectDir), 0.0), 35.0);
      vec3 specular = uKs * light_atten_coff * spec;  
      
      gl_FragColor = vec4(pow((ambient + diffuse + specular), vec3(1.0/2.2)), 1.0);     
      //gl_FragColor = vec4(pow((diffuse), vec3(1.0/2.2)), 1.0);    

      //gl_FragColor = vec4( color, 1.0 );
      //gl_FragColor = vec4(0.1);
       
    }
&lt;/script&gt;
</code></pre>
<h3 id="总代码">总代码</h3>
<pre><code class="language-javascript">&lt;!DOCTYPE html&gt;
&lt;html lang=&quot;en&quot;&gt;

&lt;head&gt;
  &lt;meta charset=&quot;UTF-8&quot;&gt;
  &lt;title&gt;源码对应电子书:百度&quot;three.js 郭隆邦&quot;&lt;/title&gt;
  &lt;style&gt;
    body {
      margin: 0;
      overflow: hidden;
      /* 隐藏body窗口区域滚动条 */
    }
  &lt;/style&gt;
  &lt;!--引入three.js三维引擎--&gt;
  &lt;script src=&quot;http://www.yanhuangxueyuan.com/versions/threejsR92/build/three.js&quot;&gt;&lt;/script&gt;
  &lt;!-- 引入threejs扩展控件OrbitControls.js --&gt;
  &lt;script src=&quot;http://www.yanhuangxueyuan.com/versions/threejsR92/examples/js/controls/OrbitControls.js&quot;&gt;&lt;/script&gt;
&lt;/head&gt;

&lt;body&gt;
  &lt;!--**********************Shader程序***************************--&gt;

  &lt;script id=&quot;vertexShader&quot; type=&quot;x-shader/x-vertex&quot;&gt;
    attribute vec3 aNormalPosition;
    attribute vec2 aTextureCoord;
    varying highp vec2 vTextureCoord;
    varying highp vec3 vFragPos;
    varying highp vec3 vNormal;
    /*
    normal,position以及摄像机位置需要使用three.js内置参数
    */
    
    void main(void) {
    
      vFragPos = position;
      vNormal = normal;
      gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);  
      vTextureCoord = uv;
    
    }
    


&lt;/script&gt;

  &lt;script id=&quot;fragmentShader&quot; type=&quot;x-shader/x-fragment&quot;&gt;
    #ifdef GL_ES
    precision mediump float;  
    #endif
    uniform sampler2D uSampler;
    uniform vec3 uKd;
    uniform vec3 uKs;
    uniform vec3 lightPosition;
    uniform float uLightIntensity;
    uniform int uTextureSample;
    
    varying highp vec2 vTextureCoord;
    varying highp vec3 vFragPos;
    varying highp vec3 vNormal;
    
    void main(void) {
      vec3 color;
      if (uTextureSample == 1) {
        color = pow(texture2D(uSampler, vTextureCoord).rgb, vec3(2.2));
      } else {
        color = uKd;
      }


      vec3 ambient = 0.05 * color;
    
      vec3 lightDir = normalize(lightPosition - vFragPos);
      vec3 normal = normalize(vNormal);
      float diff = max(dot(lightDir, normal), 0.0);
      float light_atten_coff = uLightIntensity / length(lightPosition - vFragPos);
      vec3 diffuse =  diff * light_atten_coff * color;
    
      vec3 viewDir = normalize(cameraPosition - vFragPos);
      float spec = 0.0;
      vec3 reflectDir = reflect(-lightDir, normal);
      spec = pow (max(dot(viewDir, reflectDir), 0.0), 35.0);
      vec3 specular = uKs * light_atten_coff * spec;  
      
      gl_FragColor = vec4(pow((ambient + diffuse + specular), vec3(1.0/2.2)), 1.0);     
      //gl_FragColor = vec4(pow((diffuse), vec3(1.0/2.2)), 1.0);    

      //gl_FragColor = vec4( color, 1.0 );
      //gl_FragColor = vec4(0.1);
       
    }
    
    

&lt;/script&gt;


  &lt;script&gt;
    /**
     * 创建场景对象Scene
     */
    var scene = new THREE.Scene();

    /**
     * 光源设置
     */
    //点光源
    var point = new THREE.PointLight(0xffffff);
    point.position.set(400, 200, 300); //点光源位置
    scene.add(point); //点光源添加到场景中
    //环境光
    var ambient = new THREE.AmbientLight(0x888888);
    scene.add(ambient);
    /**
     * 相机设置
     */
    var width = window.innerWidth; //窗口宽度
    var height = window.innerHeight; //窗口高度
    var k = width / height; //窗口宽高比
    var s = 150; //三维场景显示范围控制系数，系数越大，显示的范围越大
    //创建相机对象
    var camera = new THREE.OrthographicCamera(-s * k, s * k, s, -s, 1, 1000);
    camera.position.set(200, 300, 200); //设置相机位置
    // camera.position.set(0, 0, 200); //设置相机位置
    camera.lookAt(scene.position); //设置相机方向(指向的场景对象)

    /**
     * 创建网格模型
     */
    // var geometry = new THREE.BoxGeometry(100, 100, 100); //立方体
    // var geometry = new THREE.PlaneGeometry(400, 400); //矩形平面
    var geometry = new THREE.SphereGeometry(100, 25, 25); //球体
    // TextureLoader创建一个纹理加载器对象，可以加载图片作为几何体纹理
    var textureLoader = new THREE.TextureLoader();
    // 加载纹理贴图
    var texture = textureLoader.load('./Earth.png');
    var material = new THREE.MeshPhongMaterial({
      map: texture, // 普通颜色纹理贴图
    }); //材质对象Material
    var mesh = new THREE.Mesh(geometry, material); //网格模型对象Mesh
    scene.add(mesh); //网格模型添加到场景中
    var uniforms;
    uniforms = {
      uSampler: {//采样的图片
        value: texture,
      },
      uTextureSample: {//采样选择 1为贴图 2为不带贴图
        value: 1
      },
      uKd: {
        value: new THREE.Vector3(0.05, 0.05, 0.05)//控制满反射系数
      },
      uKs: {
        value: new THREE.Vector3(0.5, 0.5, 0.5)//控制高光系数
      },
      lightPosition: {//光源位置
        value: point.position
      },
      uLightIntensity: {
        value: 1155.0//光照强度
      }
    };
    var material_raw = new THREE.ShaderMaterial({
      uniforms: uniforms,
      vertexShader: document.getElementById('vertexShader').textContent,
      fragmentShader: document.getElementById('fragmentShader').textContent,
    });

    var mesh_raw = new THREE.Mesh(geometry, material_raw);
    mesh_raw.position.x = (mesh.position.x + 100 * 2);
    mesh_raw.position.z = (mesh.position.z + 100 * 2);
    scene.add(mesh_raw);

    /**
     * 创建渲染器对象
     */
    var renderer = new THREE.WebGLRenderer();
    renderer.setSize(width, height); //设置渲染区域尺寸
    renderer.setClearColor(0xb9d3ff, 1); //设置背景颜色
    document.body.appendChild(renderer.domElement); //body元素中插入canvas对象

    // 渲染函数
    function render() {
      renderer.render(scene, camera); //执行渲染操作
      requestAnimationFrame(render); //请求再次执行渲染函数render，渲染下一帧
    }
    render();
    //创建控件对象  相机对象camera作为参数   控件可以监听鼠标的变化，改变相机对象的属性
    var controls = new THREE.OrbitControls(camera, renderer.domElement);
    //监听鼠标事件，触发渲染函数，更新canvas画布渲染效果
    // controls.addEventListener('change', render);
  &lt;/script&gt;

&lt;/body&gt;

&lt;/html&gt;
</code></pre>
<h2 id="要注意的坑">要注意的坑</h2>
<p><strong>uniform 传入的变量 和 顶点着色器 片元着色器 接受的变量</strong></p>
<p>ShaderMaterial的vertexshader和fragmentshader是有默认变量的。【如果不想three.js有任何内置变量影响你的shader，那么请使用<a href="http://www.yanhuangxueyuan.com/threejs/docs/index.html#api/zh/materials/RawShaderMaterial">RawShaderMaterial</a>】</p>
<p>这一点three.js文档里提到了但是没有指出默认变量是啥，最后利用浏览器F12调试工具发现</p>
<figure data-type="image" tabindex="4"><img src="https://logic-three-body.github.io//post-images/1621432247536.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="5"><img src="https://logic-three-body.github.io//post-images/1621432267313.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="6"><img src="https://logic-three-body.github.io//post-images/1621432273276.png" alt="" loading="lazy"></figure>
<h2 id="感悟">感悟</h2>
<p>理解算法理论之后利用编程实现仍要考虑诸多问题，比如和api的接口，这次编写shader正因为接口不对顶点没有出进去所以一直绘制出现问题，当顶点、法线、光照方向、相机方向等考虑正确后算法才可以发挥效果</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[GAMES101->assignment3 Shader and Graphic pipeline]]></title>
        <id>https://logic-three-body.github.io/post/games101-greaterassignment3-shader-and-graphic-pipeline/</id>
        <link href="https://logic-three-body.github.io/post/games101-greaterassignment3-shader-and-graphic-pipeline/">
        </link>
        <updated>2021-05-19T12:30:37.000Z</updated>
        <content type="html"><![CDATA[<p>项目地址：<a href="https://github.com/logic-three-body/GameS101_IntroductionTOcomputerGraph/tree/%E4%BD%9C%E4%B8%9A1/Shader">click</a></p>
<p>渲染图像：<a href="https://github.com/logic-three-body/GameS101_IntroductionTOcomputerGraph/tree/%E4%BD%9C%E4%B8%9A1/Shader/image">click</a></p>
<p>模型支持在视图中<strong>旋转</strong>（利用<a href="https://github.com/logic-three-body/GameS101_IntroductionTOcomputerGraph/tree/%E4%BD%9C%E4%B8%9A1/Roate_Project">assignment1</a>旋转三角形方法）</p>
<h2 id="mvp部分">MVP部分</h2>
<p>model变换中 变量<strong>coef</strong>是模型的缩放因子</p>
<pre><code class="language-c++">Eigen::Matrix4f get_view_matrix(Eigen::Vector3f eye_pos)
{
	Eigen::Matrix4f view = Eigen::Matrix4f::Identity();

	Eigen::Matrix4f translate;
	translate &lt;&lt; 1, 0, 0, -eye_pos[0],
		0, 1, 0, -eye_pos[1],
		0, 0, 1, -eye_pos[2],
		0, 0, 0, 1;

	view = translate * view;

	return view;
}

Eigen::Matrix4f get_model_matrix(float angle)
{
	Eigen::Matrix4f rotation;
	angle = angle * MY_PI / 180.f;
	rotation &lt;&lt; cos(angle), 0, sin(angle), 0,
		0, 1, 0, 0,
		-sin(angle), 0, cos(angle), 0,
		0, 0, 0, 1;

	Eigen::Matrix4f scale;
	float coef = 1.0f;//缩放因子
	coef = 2.5f;
	//coef = 5.0f;
	//coef = 7.0f;
	coef = 8.0f;
	scale &lt;&lt; coef, 0, 0, 0,
		0, coef, 0, 0,
		0, 0, coef, 0,
		0, 0, 0, 1;

	Eigen::Matrix4f translate;
	translate &lt;&lt; 1, 0, 0, 0,
		0, 1, 0, 0,
		0, 0, 1, 0,
		0, 0, 0, 1;

	return translate * rotation * scale;
}

Eigen::Matrix4f get_projection_matrix(float eye_fov, float aspect_ratio, float zNear, float zFar)
{
	Eigen::Matrix4f projection;
	float top = -tan(DEG2RAD(eye_fov / 2.0f) * abs(zNear));
	float right = top * aspect_ratio;

	projection &lt;&lt; zNear / right, 0, 0, 0,
		0, zNear / top, 0, 0,
		0, 0, (zNear + zFar) / (zNear - zFar), (2 * zNear*zFar) / (zFar - zNear),
		0, 0, 1, 0;
	return projection;

}
</code></pre>
<h2 id="shader部分">shader部分</h2>
<h3 id="纹理着色器">纹理着色器</h3>
<pre><code class="language-C++">Eigen::Vector3f texture_fragment_shader(const fragment_shader_payload&amp; payload)
{
	Eigen::Vector3f return_color = { 0, 0, 0 };
	if (payload.texture)
	{
		// TODO: Get the texture value at the texture coordinates of the current fragment
		return_color = payload.texture-&gt;getColor(payload.tex_coords.x(), payload.tex_coords.y());
	}
	Eigen::Vector3f texture_color;
	texture_color &lt;&lt; return_color.x(), return_color.y(), return_color.z();

	Eigen::Vector3f ka = Eigen::Vector3f(0.005, 0.005, 0.005);
	Eigen::Vector3f kd = texture_color / 255.f;
	Eigen::Vector3f ks = Eigen::Vector3f(0.7937, 0.7937, 0.7937);

	auto l1 = light{ {20, 20, 20}, {500, 500, 500} };
	auto l2 = light{ {-20, 20, 0}, {500, 500, 500} };

	std::vector&lt;light&gt; lights = { l1, l2 };
	Eigen::Vector3f amb_light_intensity{ 10, 10, 10 };
	Eigen::Vector3f eye_pos{ 0, 0, 10 };

	float p = 150;

	Eigen::Vector3f color = texture_color;
	Eigen::Vector3f point = payload.view_pos;
	Eigen::Vector3f normal = payload.normal;

	Eigen::Vector3f result_color = { 0, 0, 0 };
	Vector3f view_dir = (eye_pos - point).normalized();
	for (auto&amp; light : lights)
	{
		// TODO: For each light source in the code, calculate what the *ambient*, *diffuse*, and *specular* 
		// components are. Then, accumulate that result on the *result_color* object.
		float r2 = (light.position - point).squaredNorm();
		Vector3f diffsue(0, 0, 0);
		Vector3f specular(0, 0, 0);
		Vector3f ambient(0, 0, 0);
		Vector3f light_dir = (light.position - point).normalized();

		for (size_t i = 0; i &lt; 3; i++)
		{
			Vector3f half_v = (view_dir + light_dir).normalized(); // half
			float intensity = light.intensity[i] / r2;
			diffsue[i] = kd[i] * intensity * std::max(0.0f, normal.dot(light_dir));
			specular[i] = ks[i] * intensity * std::pow(std::max(0.0f, normal.dot(half_v)), p);
			ambient[i] = amb_light_intensity[i] * ka[i];
		}
		result_color += diffsue;
		result_color += specular;
		result_color += ambient;
	}

	return result_color * 255.f;
}
</code></pre>
<h3 id="法线贴图着色器">法线贴图着色器</h3>
<pre><code class="language-C++">Eigen::Vector3f normal_fragment_shader(const fragment_shader_payload&amp; payload)
{
	Eigen::Vector3f return_color = (payload.normal.head&lt;3&gt;().normalized() + Eigen::Vector3f(1.0f, 1.0f, 1.0f)) / 2.f;
	Eigen::Vector3f result;
	result &lt;&lt; return_color.x() * 255, return_color.y() * 255, return_color.z() * 255;
	return result;
}
</code></pre>
<h3 id="凹凸贴图着色器">凹凸贴图着色器</h3>
<pre><code class="language-C++">Eigen::Vector3f bump_fragment_shader(const fragment_shader_payload&amp; payload)
{

	Eigen::Vector3f ka = Eigen::Vector3f(0.005, 0.005, 0.005);
	Eigen::Vector3f kd = payload.color;
	Eigen::Vector3f ks = Eigen::Vector3f(0.7937, 0.7937, 0.7937);

	auto l1 = light{ {20, 20, 20}, {500, 500, 500} };
	auto l2 = light{ {-20, 20, 0}, {500, 500, 500} };

	std::vector&lt;light&gt; lights = { l1, l2 };
	Eigen::Vector3f amb_light_intensity{ 10, 10, 10 };
	Eigen::Vector3f eye_pos{ 0, 0, 10 };

	float p = 150;

	Eigen::Vector3f color = payload.color;
	Eigen::Vector3f point = payload.view_pos;
	Eigen::Vector3f normal = payload.normal.normalized();


	float kh = 0.2, kn = 0.1;

	// TODO: Implement bump mapping here
	// Let n = normal = (x, y, z)
	// Vector t = (x*y/sqrt(x*x+z*z),sqrt(x*x+z*z),z*y/sqrt(x*x+z*z))
	// Vector b = n cross product t
	// Matrix TBN = [t b n]
	// dU = kh * kn * (h(u+1/w,v)-h(u,v))
	// dV = kh * kn * (h(u,v+1/h)-h(u,v))
	// Vector ln = (-dU, -dV, 1)
	// Normal n = normalize(TBN * ln)

	float x = normal.x();
	float y = normal.y();
	float z = normal.z();
	Vector3f t(x*y / sqrt(x*x + z * z), sqrt(x*x + z * z), z*y / sqrt(x*x + z * z));
	Vector3f b = normal.cross(t);

	Matrix3f TBN;
	TBN.col(0) = t;
	TBN.col(1) = b;
	TBN.col(2) = normal;

	int w = payload.texture-&gt;width;
	int h = payload.texture-&gt;height;
	float u = payload.tex_coords.x();
	float v = payload.tex_coords.y();
	payload.texture-&gt;getColor(u, v);

	auto huv = payload.texture-&gt;getColor(u, v).norm();

	float dU = kh * kn * (payload.texture-&gt;getColor(u + 1.0f / w, v).norm() - huv);
	float dV = kh * kn * (payload.texture-&gt;getColor(u, v + 1.0f / h).norm() - huv);

	Vector3f ln(-dU, -dV, 1);
	Vector3f n = (TBN * ln).normalized();

	Eigen::Vector3f result_color = n;
	return result_color * 255.f;
}
</code></pre>
<h3 id="置换贴图着色器">置换贴图着色器</h3>
<pre><code class="language-C++">Eigen::Vector3f displacement_fragment_shader(const fragment_shader_payload&amp; payload)
{

	Eigen::Vector3f ka = Eigen::Vector3f(0.005, 0.005, 0.005);
	Eigen::Vector3f kd = payload.color;
	Eigen::Vector3f ks = Eigen::Vector3f(0.7937, 0.7937, 0.7937);

	auto l1 = light{ {20, 20, 20}, {500, 500, 500} };
	auto l2 = light{ {-20, 20, 0}, {500, 500, 500} };

	std::vector&lt;light&gt; lights = { l1, l2 };
	Eigen::Vector3f amb_light_intensity{ 10, 10, 10 };
	Eigen::Vector3f eye_pos{ 0, 0, 10 };

	Eigen::Vector3f color = payload.color;
	Eigen::Vector3f point = payload.view_pos;
	Eigen::Vector3f normal = payload.normal;

	float kh = 0.2, kn = 0.1;

	// TODO: Implement displacement mapping here
	// Let n = normal = (x, y, z)
	// Vector t = (x*y/sqrt(x*x+z*z),sqrt(x*x+z*z),z*y/sqrt(x*x+z*z))
	// Vector b = n cross product t
	// Matrix TBN = [t b n]
	// dU = kh * kn * (h(u+1/w,v)-h(u,v))
	// dV = kh * kn * (h(u,v+1/h)-h(u,v))
	// Vector ln = (-dU, -dV, 1)
	// Position p = p + kn * n * h(u,v)
	// Normal n = normalize(TBN * ln)


	float x = normal.x();
	float y = normal.y();
	float z = normal.z();
	Vector3f t(x*y / sqrt(x*x + z * z), sqrt(x*x + z * z), z*y / sqrt(x*x + z * z));
	Vector3f b = normal.cross(t);

	Matrix3f TBN;
	TBN.col(0) = t.normalized();
	TBN.col(1) = b.normalized();
	TBN.col(2) = normal;

	int w = payload.texture-&gt;width;
	int h = payload.texture-&gt;height;
	float u = payload.tex_coords.x();
	float v = payload.tex_coords.y();
	payload.texture-&gt;getColor(u, v);

	auto huv = payload.texture-&gt;getColor(u, v).norm();

	float dU = kh * kn * (payload.texture-&gt;getColor(u + 1.0f / w, v).norm() - huv);
	float dV = kh * kn * (payload.texture-&gt;getColor(u, v + 1.0f / h).norm() - huv);

	Vector3f ln(-dU, -dV, 1);
	Vector3f n = (TBN * ln).normalized();
	Vector3f p = point + n * huv * kn;

	Eigen::Vector3f result_color = { 0, 0, 0 };
	Vector3f view_dir = (eye_pos - p).normalized();
	for (auto&amp; light : lights)
	{
		// TODO: For each light source in the code, calculate what the *ambient*, *diffuse*, and *specular* 
		// components are. Then, accumulate that result on the *result_color* object.
		float r2 = (light.position - p).squaredNorm();
		Vector3f diffsue(0, 0, 0);
		Vector3f specular(0, 0, 0);
		Vector3f ambient(0, 0, 0);
		Vector3f light_dir = (light.position - p).normalized();

		for (size_t i = 0; i &lt; 3; i++)
		{
			Vector3f h = (view_dir + light_dir).normalized(); // half
			float intensity = light.intensity[i] / r2;
			diffsue[i] = kd[i] * intensity * std::max(0.0f, normal.dot(light_dir));
			specular[i] = ks[i] * intensity * std::pow(std::max(0.0f, normal.dot(h)), 150);
			ambient[i] = amb_light_intensity[i] * ka[i];
		}
		result_color += diffsue;
		result_color += specular;
		result_color += ambient;
	}

	return result_color * 255.f;
}
</code></pre>
<h3 id="blin-phong模型着色器">Blin-Phong模型着色器</h3>
<pre><code class="language-C++">Eigen::Vector3f texture_fragment_shader(const fragment_shader_payload&amp; payload)
{
	Eigen::Vector3f return_color = { 0, 0, 0 };
	if (payload.texture)
	{
		// TODO: Get the texture value at the texture coordinates of the current fragment
		return_color = payload.texture-&gt;getColor(payload.tex_coords.x(), payload.tex_coords.y());
	}
	Eigen::Vector3f texture_color;
	texture_color &lt;&lt; return_color.x(), return_color.y(), return_color.z();

	Eigen::Vector3f ka = Eigen::Vector3f(0.005, 0.005, 0.005);
	Eigen::Vector3f kd = texture_color / 255.f;
	Eigen::Vector3f ks = Eigen::Vector3f(0.7937, 0.7937, 0.7937);

	auto l1 = light{ {20, 20, 20}, {500, 500, 500} };
	auto l2 = light{ {-20, 20, 0}, {500, 500, 500} };

	std::vector&lt;light&gt; lights = { l1, l2 };
	Eigen::Vector3f amb_light_intensity{ 10, 10, 10 };
	Eigen::Vector3f eye_pos{ 0, 0, 10 };

	float p = 150;

	Eigen::Vector3f color = texture_color;
	Eigen::Vector3f point = payload.view_pos;
	Eigen::Vector3f normal = payload.normal;

	Eigen::Vector3f result_color = { 0, 0, 0 };
	Vector3f view_dir = (eye_pos - point).normalized();
	for (auto&amp; light : lights)
	{
		// TODO: For each light source in the code, calculate what the *ambient*, *diffuse*, and *specular* 
		// components are. Then, accumulate that result on the *result_color* object.
		float r2 = (light.position - point).squaredNorm();
		Vector3f diffsue(0, 0, 0);
		Vector3f specular(0, 0, 0);
		Vector3f ambient(0, 0, 0);
		Vector3f light_dir = (light.position - point).normalized();

		for (size_t i = 0; i &lt; 3; i++)
		{
			Vector3f half_v = (view_dir + light_dir).normalized(); // half
			float intensity = light.intensity[i] / r2;
			diffsue[i] = kd[i] * intensity * std::max(0.0f, normal.dot(light_dir));
			specular[i] = ks[i] * intensity * std::pow(std::max(0.0f, normal.dot(half_v)), p);
			ambient[i] = amb_light_intensity[i] * ka[i];
		}
		result_color += diffsue;
		result_color += specular;
		result_color += ambient;
	}

	return result_color * 255.f;
}
</code></pre>
<h2 id="光栅化部分">光栅化部分</h2>
<pre><code class="language-C++">void rst::rasterizer::rasterize_triangle(const Triangle&amp; t, const std::array&lt;Eigen::Vector3f, 3&gt;&amp; view_pos) 
{
	// TODO : Find out the bounding box of current triangle.
	float aabb_minx = 0;
	float aabb_miny = 0;
	float aabb_maxx = 0;
	float aabb_maxy = 0;
	for (size_t i = 0; i &lt; 3; i++)
	{
		const Vector4f&amp; p = t.v[i];
		if (i == 0)
		{
			aabb_minx = aabb_maxx = p.x();
			aabb_miny = aabb_maxy = p.y();
			continue;
		}

		aabb_minx = p.x() &lt; aabb_minx ? p.x() : aabb_minx;
		aabb_miny = p.y() &lt; aabb_miny ? p.y() : aabb_miny;

		aabb_maxx = p.x() &gt; aabb_maxx ? p.x() : aabb_maxx;
		aabb_maxy = p.y() &gt; aabb_maxy ? p.y() : aabb_maxy;
	}

	// iterate through the pixel and find if the current pixel is inside the triangle
	auto v = t.v;
	for (int x = (int)aabb_minx; x &lt; aabb_maxx; x++)
	{
		for (int y = (int)aabb_miny; y &lt; aabb_maxy; y++)
		{

			if (!insideTriangle(x, y, t.v)) continue;
			// TODO: Inside your rasterization loop:
			//    * v[i].w() is the vertex view space depth value z.
			//    * Z is interpolated view space depth for the current pixel
			//    * zp is depth between zNear and zFar, used for z-buffer
			auto[alpha, beta, gamma] = computeBarycentric2D(x, y, t.v);


			float Z = 1.0 / (alpha / v[0].w() + beta / v[1].w() + gamma / v[2].w());
			float zp = alpha * v[0].z() / v[0].w() + beta * v[1].z() / v[1].w() + gamma * v[2].z() / v[2].w();
			zp *= Z;

			int buf_index = get_index(x, y);
			if (zp &gt;= depth_buf[buf_index]) continue;

			depth_buf[buf_index] = zp;

			// TODO: Interpolate the attributes:
			// auto interpolated_color
			// auto interpolated_normal
			// auto interpolated_texcoords
			// auto interpolated_shadingcoords

			auto interpolated_color = interpolate(alpha, beta, gamma, t.color[0], t.color[1], t.color[2], 1);
			auto interpolated_normal = interpolate(alpha, beta, gamma, t.normal[0], t.normal[1], t.normal[2], 1);
			auto interpolated_texcoords = interpolate(alpha, beta, gamma, t.tex_coords[0], t.tex_coords[1], t.tex_coords[2], 1);
			auto interpolated_viewpos = interpolate(alpha, beta, gamma, view_pos[0], view_pos[1], view_pos[2], 1);
            
   // Use: fragment_shader_payload payload( interpolated_color, interpolated_normal.normalized(), interpolated_texcoords, texture ? &amp;*texture : nullptr);
    // Use: payload.view_pos = interpolated_shadingcoords;
    // Use: Instead of passing the triangle's color directly to the frame buffer, pass the color to the shaders first to get the final color;
    // Use: auto pixel_color = fragment_shader(payload);
            
			fragment_shader_payload payload(interpolated_color, interpolated_normal.normalized(), interpolated_texcoords, texture ? &amp;*texture : nullptr);
			payload.view_pos = interpolated_viewpos;
			auto pixel_color = fragment_shader(payload);//注入shader
			set_pixel(Vector2i(x, y), pixel_color);
		}
	}	
}
</code></pre>
<h2 id="渲染图">渲染图</h2>
<h3 id="小牛spot">小牛spot</h3>
<h4 id="texture">texture</h4>
<figure data-type="image" tabindex="1"><img src="https://github.com/logic-three-body/GameS101_IntroductionTOcomputerGraph/blob/%E4%BD%9C%E4%B8%9A1/Shader/image/spot/snapshot/texture/frame1.png?raw=true" alt="frame1.png" loading="lazy"></figure>
<figure data-type="image" tabindex="2"><img src="https://github.com/logic-three-body/GameS101_IntroductionTOcomputerGraph/blob/%E4%BD%9C%E4%B8%9A1/Shader/image/spot/snapshot/tex.gif?raw=true" alt="tex.gif" loading="lazy"></figure>
<h4 id="normal">normal</h4>
<figure data-type="image" tabindex="3"><img src="https://github.com/logic-three-body/GameS101_IntroductionTOcomputerGraph/blob/%E4%BD%9C%E4%B8%9A1/Shader/image/spot/snapshot/normal/frame1.png?raw=true" alt="frame1.png" loading="lazy"></figure>
<figure data-type="image" tabindex="4"><img src="https://github.com/logic-three-body/GameS101_IntroductionTOcomputerGraph/blob/%E4%BD%9C%E4%B8%9A1/Shader/image/spot/snapshot/norm.gif?raw=true" alt="norm.gif" loading="lazy"></figure>
<h4 id="bump">bump</h4>
<figure data-type="image" tabindex="5"><img src="https://github.com/logic-three-body/GameS101_IntroductionTOcomputerGraph/blob/%E4%BD%9C%E4%B8%9A1/Shader/image/spot/snapshot/bump/frame1.png?raw=true" alt="frame1.png" loading="lazy"></figure>
<figure data-type="image" tabindex="6"><img src="https://github.com/logic-three-body/GameS101_IntroductionTOcomputerGraph/blob/%E4%BD%9C%E4%B8%9A1/Shader/image/spot/snapshot/bump.gif?raw=true" alt="bump.gif" loading="lazy"></figure>
<h4 id="displacement">displacement</h4>
<figure data-type="image" tabindex="7"><img src="https://github.com/logic-three-body/GameS101_IntroductionTOcomputerGraph/blob/%E4%BD%9C%E4%B8%9A1/Shader/image/spot/snapshot/displacement/frame1.png?raw=true" alt="frame1.png" loading="lazy"></figure>
<figure data-type="image" tabindex="8"><img src="https://github.com/logic-three-body/GameS101_IntroductionTOcomputerGraph/blob/%E4%BD%9C%E4%B8%9A1/Shader/image/spot/snapshot/displacement.gif?raw=true" alt="displacement.gif" loading="lazy"></figure>
<h4 id="phong">phong</h4>
<figure data-type="image" tabindex="9"><img src="https://github.com/logic-three-body/GameS101_IntroductionTOcomputerGraph/blob/%E4%BD%9C%E4%B8%9A1/Shader/image/spot/snapshot/Blin-phong/frame1.png?raw=true" alt="frame1.png" loading="lazy"></figure>
<figure data-type="image" tabindex="10"><img src="https://github.com/logic-three-body/GameS101_IntroductionTOcomputerGraph/blob/%E4%BD%9C%E4%B8%9A1/Shader/image/spot/snapshot/Blin-phong.gif?raw=true" alt="Blin-phong.gif" loading="lazy"></figure>
<h3 id="bunny">bunny</h3>
<h4 id="texture-2">texture</h4>
<figure data-type="image" tabindex="11"><img src="https://github.com/logic-three-body/GameS101_IntroductionTOcomputerGraph/blob/%E4%BD%9C%E4%B8%9A1/Shader/image/bunny/snapshot/tex/frame171.png?raw=true" alt="frame171.png" loading="lazy"></figure>
<figure data-type="image" tabindex="12"><img src="https://github.com/logic-three-body/GameS101_IntroductionTOcomputerGraph/blob/%E4%BD%9C%E4%B8%9A1/Shader/image/bunny/snapshot/tex.gif?raw=true" alt="tex.gif" loading="lazy"></figure>
<h4 id="normal-2">normal</h4>
<figure data-type="image" tabindex="13"><img src="https://github.com/logic-three-body/GameS101_IntroductionTOcomputerGraph/blob/%E4%BD%9C%E4%B8%9A1/Shader/image/bunny/snapshot/norm/frame4.png?raw=true" alt="frame4.png" loading="lazy"></figure>
<figure data-type="image" tabindex="14"><img src="https://github.com/logic-three-body/GameS101_IntroductionTOcomputerGraph/blob/%E4%BD%9C%E4%B8%9A1/Shader/image/bunny/snapshot/norm.gif?raw=true" alt="norm.gif" loading="lazy"></figure>
<h3 id="dragon">dragon</h3>
<h4 id="normal-3">normal</h4>
<h5 id="1k">1K</h5>
<figure data-type="image" tabindex="15"><img src="https://github.com/logic-three-body/GameS101_IntroductionTOcomputerGraph/blob/%E4%BD%9C%E4%B8%9A1/Shader/image/dragon/snapshot/size1000.png?raw=true" alt="size1000.png" loading="lazy"></figure>
<h5 id="2k">2K</h5>
<figure data-type="image" tabindex="16"><img src="https://github.com/logic-three-body/GameS101_IntroductionTOcomputerGraph/blob/%E4%BD%9C%E4%B8%9A1/Shader/image/dragon/snapshot/size2000.png?raw=true" alt="size2000.png" loading="lazy"></figure>
<h5 id="8k">8K</h5>
<figure data-type="image" tabindex="17"><img src="https://github.com/logic-three-body/GameS101_IntroductionTOcomputerGraph/blob/%E4%BD%9C%E4%B8%9A1/Shader/image/dragon/snapshot/size8000.png?raw=true" alt="size8000.png" loading="lazy"></figure>
<figure data-type="image" tabindex="18"><img src="https://github.com/logic-three-body/GameS101_IntroductionTOcomputerGraph/blob/%E4%BD%9C%E4%B8%9A1/Shader/image/dragon/norm.gif?raw=true" alt="norm.gif" loading="lazy"></figure>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[数字媒体技术期末总结]]></title>
        <id>https://logic-three-body.github.io/post/shu-zi-mei-ti-ji-zhu-qi-mo-zong-jie/</id>
        <link href="https://logic-three-body.github.io/post/shu-zi-mei-ti-ji-zhu-qi-mo-zong-jie/">
        </link>
        <updated>2021-05-17T08:56:12.000Z</updated>
        <content type="html"><![CDATA[<h1 id="前言">前言</h1>
<p>数字媒体技术基础课件总结浓缩，<strong>幕布</strong>版可以访问<a href="https://share.mubu.com/doc/7p7gHyyHh1q">这里</a></p>
<h1 id="数字媒体技术概论-专题一">数字媒体技术概论 专题一</h1>
<h2 id="媒体-medium">媒体 medium</h2>
<ul>
<li>
<p>交流传播工具</p>
<ul>
<li>广播 广告</li>
</ul>
</li>
<li>
<p>媒介 - 信息</p>
</li>
<li>
<p>类型</p>
<ul>
<li>
<p>显示媒体</p>
</li>
<li>
<p>感觉媒体</p>
</li>
<li>
<p>存储媒体</p>
</li>
<li>
<p>表示媒体</p>
</li>
<li>
<p>传输媒体</p>
</li>
</ul>
</li>
<li>
<p>多媒体</p>
<ul>
<li>
<p>计算机技术 数字通信网络</p>
</li>
<li>
<p>文本</p>
</li>
<li>
<p>图形</p>
</li>
<li>
<p>图像</p>
</li>
<li>
<p>声音</p>
</li>
</ul>
</li>
</ul>
<h2 id="数字媒体">数字媒体</h2>
<ul>
<li>
<p>二进制</p>
</li>
<li>
<p>数字化</p>
<ul>
<li>
<p>模拟信号</p>
<ul>
<li>
<p>连续</p>
</li>
<li>
<p>人脑处理</p>
</li>
<li>
<p>如图<img src="https://api2.mubu.com/v3/document_image/3924B04F0F104E961620967024.jpg" alt="img" loading="lazy"></p>
</li>
</ul>
</li>
<li>
<p>数字信号</p>
<ul>
<li>
<p>离散</p>
</li>
<li>
<p>计算机处理</p>
</li>
<li>
<p>如图<img src="https://api2.mubu.com/v3/document_image/ECF548FC2C4A4BFD1620967031.jpg" alt="img" loading="lazy"></p>
</li>
</ul>
</li>
<li>
<p>模/数转换（A/D）</p>
</li>
<li>
<p>数/模转换（D/A）</p>
</li>
</ul>
</li>
<li>
<p>香农 信息传递模型</p>
</li>
<li>
<p>分类</p>
<ul>
<li>
<p>时间</p>
<ul>
<li>
<p>静止</p>
</li>
<li>
<p>连续</p>
</li>
</ul>
</li>
<li>
<p>来源</p>
<ul>
<li>
<p>自然</p>
</li>
<li>
<p>合成</p>
</li>
</ul>
</li>
<li>
<p>组成</p>
<ul>
<li>
<p>单一</p>
</li>
<li>
<p>多</p>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>传播模式</p>
<ul>
<li>信息论的通信模式
<ul>
<li>如图<img src="https://api2.mubu.com/v3/document_image/90ECC2CBA319411C1620967135.jpg" alt="img" loading="lazy"></li>
</ul>
</li>
</ul>
</li>
<li>
<p>内涵</p>
<ul>
<li>
<p>技术 艺术 （接下来七个专题）</p>
<ul>
<li>
<p>数字声音</p>
</li>
<li>
<p>数字图像</p>
</li>
<li>
<p>数字视频</p>
</li>
<li>
<p>数字动画</p>
</li>
<li>
<p>数字压缩</p>
</li>
<li>
<p>数字储存</p>
</li>
<li>
<p>数字管理与保护</p>
</li>
<li>
<p>数字传输</p>
</li>
</ul>
</li>
<li>
<p>流程</p>
<ul>
<li>如图<img src="https://api2.mubu.com/v3/document_image/5CC91748087D49BC1620967244.jpg" alt="img" loading="lazy"></li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="数字信息">数字信息</h2>
<ul>
<li>
<p>获取 输出</p>
</li>
<li>
<p>存储</p>
<ul>
<li>
<p>磁存储</p>
<ul>
<li>磁盘 磁带</li>
</ul>
</li>
<li>
<p>光存储</p>
<ul>
<li>
<p>CD VCD</p>
</li>
<li>
<p>蓝光存储</p>
</li>
</ul>
</li>
<li>
<p>半导体存储</p>
<ul>
<li>RAM ROM</li>
</ul>
</li>
</ul>
</li>
<li>
<p>处理 生成</p>
<ul>
<li>
<p>来源</p>
<ul>
<li>
<p>现实生活</p>
<ul>
<li>需要数字化</li>
</ul>
</li>
<li>
<p>数字生活</p>
</li>
</ul>
</li>
<li>
<p>数字化</p>
<ul>
<li>采样 量化 编码</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="动画技术">动画技术</h2>
<ul>
<li>运动捕捉</li>
</ul>
<h2 id="传播技术">传播技术</h2>
<ul>
<li>以流stream形式传播</li>
</ul>
<h2 id="信息管理">信息管理</h2>
<ul>
<li>
<p>多媒体数据库</p>
</li>
<li>
<p>信息检索</p>
<ul>
<li>
<p>文本</p>
</li>
<li>
<p>内容</p>
<ul>
<li>
<p>颜色 场景等</p>
</li>
<li>
<p>图像</p>
<ul>
<li>
<p>特征提取</p>
</li>
<li>
<p>图像分析</p>
</li>
</ul>
</li>
<li>
<p>如图<img src="https://api2.mubu.com/v3/document_image/98C7713D43E448B31620967831.jpg" alt="img" loading="lazy"></p>
</li>
<li>
<p>未来发展方向</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="数字图像技术-专题二">数字图像技术 专题二</h1>
<h2 id="概念">概念</h2>
<ul>
<li>
<p>模拟图像</p>
<ul>
<li>空间和亮度 连续</li>
</ul>
</li>
<li>
<p>数字图像</p>
<ul>
<li>空间和亮度 有限数字表示</li>
</ul>
</li>
</ul>
<h2 id="内容">内容</h2>
<ul>
<li>
<p>图像处理</p>
<ul>
<li>图像-图像</li>
</ul>
</li>
<li>
<p>图像分析</p>
<ul>
<li>
<p>图像-信息</p>
</li>
<li>
<p>困难</p>
<ul>
<li>
<p>多义性</p>
</li>
<li>
<p>环境</p>
</li>
<li>
<p>数据</p>
</li>
</ul>
</li>
<li>
<p>如图<img src="https://api2.mubu.com/v3/document_image/F8902F213AD843441620969750.jpg" alt="img" loading="lazy"></p>
</li>
</ul>
</li>
</ul>
<h2 id="应用">应用</h2>
<ul>
<li>
<p>遥感探测</p>
</li>
<li>
<p>媒体通信</p>
</li>
<li>
<p>空间探索</p>
</li>
<li>
<p>生物医学</p>
</li>
<li>
<p>文娱产业</p>
</li>
</ul>
<h2 id="数字图像处理">数字图像处理</h2>
<h3 id="成像模型">成像模型</h3>
<ul>
<li>
<p>图像：f(x,y)   0&lt;f(x,y)&lt;A</p>
</li>
<li>
<p>可由两分量表示</p>
<ul>
<li>
<p>照射到观察景物 光总量</p>
</li>
<li>
<p>景物反射/透射    光总量</p>
</li>
</ul>
</li>
</ul>
<h3 id="采样">采样</h3>
<ul>
<li>
<p>连续图像 数字化</p>
</li>
<li>
<p>栅格grid</p>
<ul>
<li>采样点平面上排列</li>
</ul>
</li>
<li>
<p>像素 pixel/image element</p>
<ul>
<li>
<p>理论量</p>
</li>
<li>
<p>图像最小单位</p>
</li>
</ul>
</li>
</ul>
<h3 id="量化">量化</h3>
<ul>
<li>
<p>连续数值-&gt;数字等价量</p>
</li>
<li>
<p>如图<img src="https://api2.mubu.com/v3/document_image/1427DE43800B4ED31620971056.jpg" alt="img" loading="lazy"></p>
</li>
</ul>
<h3 id="分辨率">分辨率</h3>
<ul>
<li>
<p>屏幕（显示）分辨率</p>
<ul>
<li>显示器区域</li>
</ul>
</li>
<li>
<p>图像分辨率</p>
<ul>
<li>数字图像大小</li>
</ul>
</li>
<li>
<p>空间分辨率</p>
<ul>
<li>
<p>图像可分辨最小细节</p>
</li>
<li>
<p>采样间隔决定</p>
</li>
<li>
<p>空间分辨率 高 采样间隔小 图片好 图像尺寸大</p>
</li>
</ul>
</li>
<li>
<p>灰度级分辨率</p>
<ul>
<li>
<p>0-255 ： 256</p>
</li>
<li>
<p>和灰度级数有关</p>
</li>
<li>
<p>灰度级分辨率低 图像信息少 伪轮廓多</p>
</li>
<li>
<p>例如<img src="https://api2.mubu.com/v3/document_image/B44124B855A64DC81620972126.jpg" alt="img" loading="lazy"></p>
</li>
</ul>
</li>
<li>
<p>说明</p>
<ul>
<li>
<p>空间分辨率不变，采样数少 图像小</p>
</li>
<li>
<p>例如<img src="https://api2.mubu.com/v3/document_image/F7D94D386259446E1620971892.jpg" alt="img" loading="lazy"></p>
</li>
</ul>
</li>
</ul>
<h3 id="图像深度-显示深度">图像深度 显示深度</h3>
<ul>
<li>
<p>图像深度</p>
<ul>
<li>每像素 位数（灰度/颜色）</li>
</ul>
</li>
<li>
<p>显示深度</p>
<ul>
<li>显示器每点 显示颜色 位数</li>
</ul>
</li>
<li>
<p>失真</p>
<ul>
<li>显示深度&lt;图像深度</li>
</ul>
</li>
</ul>
<h3 id="图像大小计算">图像大小计算</h3>
<ul>
<li>
<p>像素总数x图像深度➗8</p>
</li>
<li>
<p>举例计算</p>
<ul>
<li>如图<img src="https://api2.mubu.com/v3/document_image/A0A3A0460BF746621620972472.jpg" alt="img" loading="lazy"></li>
</ul>
</li>
</ul>
<h3 id="表示">表示</h3>
<ul>
<li>
<p>元素</p>
<ul>
<li>
<p>矩阵</p>
</li>
<li>
<p>存储MxN图像需要位数： MxNxk</p>
</li>
</ul>
</li>
<li>
<p>坐标</p>
<ul>
<li>如图<img src="https://api2.mubu.com/v3/document_image/8E9B5C4AAEE142F41620973361.jpg" alt="img" loading="lazy"></li>
</ul>
</li>
<li>
<p>子窗口</p>
<ul>
<li>如图<img src="https://api2.mubu.com/v3/document_image/EA7E80276B474C371620973407.jpg" alt="img" loading="lazy"></li>
</ul>
</li>
</ul>
<h3 id="颜色模型">颜色模型</h3>
<ul>
<li>
<p>RGB</p>
<ul>
<li>多媒体系统输出的彩色空间</li>
</ul>
</li>
<li>
<p>HSI 色调 饱和度 亮度</p>
<ul>
<li>
<p>hue</p>
<ul>
<li>
<p>物体反射 优势波长</p>
</li>
<li>
<p>角度表示 反映物体接近光谱波长</p>
<ul>
<li>
<p>0:red</p>
</li>
<li>
<p>120:green</p>
</li>
<li>
<p>240:blue</p>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>saturation</p>
<ul>
<li>
<p>彩度/明度 色彩鲜艳程度</p>
</li>
<li>
<p>和hue的纯度有关</p>
</li>
<li>
<p>颜色深浅</p>
</li>
<li>
<p>参数：色环原点到彩色点半径长度</p>
<ul>
<li>
<p>环外饱和度：1</p>
</li>
<li>
<p>中心 ：0</p>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>intensity</p>
<ul>
<li>
<p>表面发光</p>
</li>
<li>
<p>和物体反射率成正比</p>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>YCbCr</p>
</li>
<li>
<p>CMY CMYK</p>
<ul>
<li>
<p>CMY</p>
<ul>
<li>印刷行业</li>
</ul>
</li>
<li>
<p>CMYK</p>
<ul>
<li>如图<img src="https://api2.mubu.com/v3/document_image/1EAC850D625647931620974127.jpg" alt="img" loading="lazy"></li>
</ul>
</li>
</ul>
</li>
<li>
<p>YUV</p>
<ul>
<li>
<p>Y 亮度</p>
</li>
<li>
<p>U，V 色差信号</p>
</li>
<li>
<p>PAL制 模拟电视</p>
</li>
</ul>
</li>
<li>
<p>hsi和rgb转换</p>
<ul>
<li>如图<img src="https://api2.mubu.com/v3/document_image/0D963240AF0F46ED1620973962.jpg" alt="img" loading="lazy"></li>
</ul>
</li>
<li>
<p>yuv和rgb转换</p>
<ul>
<li>如图<img src="https://api2.mubu.com/v3/document_image/40B25001694244101620974067.jpg" alt="img" loading="lazy"></li>
</ul>
</li>
</ul>
<h3 id="调色板">调色板</h3>
<ul>
<li>
<p>真彩色 伪彩色</p>
<ul>
<li>
<p>真彩色</p>
<ul>
<li>rgb各8bits表示图像</li>
</ul>
</li>
<li>
<p>伪彩色</p>
<ul>
<li>像素值为调色板索引值</li>
</ul>
</li>
</ul>
</li>
<li>
<p>16色/256色显示系统，为一个颜色表（0-15/0-255），其每一个元素对应一个rgb值</p>
</li>
<li>
<p>look up table lut</p>
</li>
</ul>
<h3 id="图像度量">图像度量</h3>
<ul>
<li>
<p>距离</p>
<ul>
<li>距离度量函数
<ul>
<li>如图<img src="https://api2.mubu.com/v3/document_image/1C6013C63F754E7B1620974642.jpg" alt="img" loading="lazy"></li>
</ul>
</li>
</ul>
</li>
<li>
<p>测量方式</p>
<ul>
<li>
<p>欧式</p>
<ul>
<li>如图<img src="https://api2.mubu.com/v3/document_image/673CBD97048A4ED61620975040.jpg" alt="img" loading="lazy"></li>
</ul>
</li>
<li>
<p>街区</p>
<ul>
<li>如图<img src="https://api2.mubu.com/v3/document_image/34C1CC6860984AAE1620975048.jpg" alt="img" loading="lazy"><img src="https://api2.mubu.com/v3/document_image/C78D605F88C24C281620975048.jpg" alt="img" loading="lazy"></li>
</ul>
</li>
<li>
<p>棋盘</p>
<ul>
<li>如图<img src="https://api2.mubu.com/v3/document_image/6CC08D7878EB4EF61620975053.jpg" alt="img" loading="lazy"></li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="直方图">直方图</h3>
<ul>
<li>
<p>定义</p>
<ul>
<li>
<p>描述灰度级函数</p>
</li>
<li>
<p>像素出现个数/频率</p>
</li>
</ul>
</li>
<li>
<p>图像对一个直方图 直方图可以对多个图像</p>
</li>
<li>
<p>应用</p>
<ul>
<li>
<p>边界选择</p>
</li>
<li>
<p>图像质量评估</p>
<ul>
<li>如图<img src="https://api2.mubu.com/v3/document_image/C3CF6679A72242C31620975254.jpg" alt="img" loading="lazy"><img src="https://api2.mubu.com/v3/document_image/2A0CC5EF34E64B751620975254.jpg" alt="img" loading="lazy"></li>
</ul>
</li>
</ul>
</li>
<li>
<p>均衡化</p>
<ul>
<li>
<p>思想</p>
<ul>
<li>像素多 展宽 像素少 缩减 达到清晰图像</li>
</ul>
</li>
<li>
<p>如图<img src="https://api2.mubu.com/v3/document_image/E2CD85B5E9174E131620975543.jpg" alt="img" loading="lazy"><img src="https://api2.mubu.com/v3/document_image/A277098D40A54AEB1620975543.jpg" alt="img" loading="lazy"></p>
</li>
</ul>
</li>
</ul>
<h3 id="位图-矢量图">位图 矢量图</h3>
<ul>
<li>
<p>位图</p>
<ul>
<li>
<p>矩阵（点阵） 栅格</p>
</li>
<li>
<p>超过分辨率 会产生锯齿</p>
</li>
<li>
<p>彩色网格/像素表示图像</p>
<ul>
<li>像素有特点位置和值</li>
</ul>
</li>
<li>
<p>软件</p>
<ul>
<li>Adobe Photoshop</li>
</ul>
</li>
</ul>
</li>
<li>
<p>矢量图</p>
<ul>
<li>
<p>数学向量记录图像</p>
<ul>
<li>
<p>线条</p>
</li>
<li>
<p>色块</p>
</li>
</ul>
</li>
<li>
<p>轮廓形状 易 修改 控制</p>
</li>
<li>
<p>和分辨率无关</p>
</li>
<li>
<p>软件</p>
<ul>
<li>Adobe illustrator</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="数字音频技术-专题三">数字音频技术 专题三</h1>
<h2 id="概念-特性">概念 特性</h2>
<ul>
<li>
<p>声音产生</p>
<ul>
<li>介质传播 连续振动的波</li>
</ul>
</li>
<li>
<p>特性</p>
<ul>
<li>
<p>频率 振幅 周期</p>
<ul>
<li>
<p>频率</p>
<ul>
<li>
<p>每秒往复振动次数</p>
</li>
<li>
<p>Hz</p>
</li>
<li>
<p>振动快 频率大 音调高</p>
</li>
<li>
<p>次声波</p>
<ul>
<li>
<p>&lt;20</p>
</li>
<li>
<p>地震 风暴</p>
</li>
</ul>
</li>
<li>
<p>超声波</p>
<ul>
<li>
<p>&gt;20</p>
</li>
<li>
<p>医学</p>
</li>
<li>
<p>清洗（牙刷）</p>
</li>
</ul>
</li>
<li>
<p>人耳可听声</p>
<ul>
<li>
<p>20~20k</p>
</li>
<li>
<p>低频 &lt;500</p>
</li>
<li>
<p>中频 500~2000</p>
</li>
<li>
<p>高频 &gt;2000</p>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>振幅</p>
<ul>
<li>
<p>偏离中心的幅度 动能 势能</p>
</li>
<li>
<p>声压大 响度大</p>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>音调 响度 音色</p>
<ul>
<li>
<p>关系（左至右）</p>
</li>
<li>
<p>频率 振幅 频谱结构</p>
</li>
</ul>
</li>
<li>
<p>傅立叶定律</p>
<ul>
<li>有限频谱 不同频率正弦波 可以叠加为 复杂波形</li>
</ul>
</li>
<li>
<p>分贝（decibel）</p>
<ul>
<li>
<p>振幅类 物理量 度量单位</p>
</li>
<li>
<p>分贝值（dB）=10lg(声源功率/基准声功率)</p>
</li>
<li>
<p>零分贝</p>
<ul>
<li>正常人听到最小音</li>
</ul>
</li>
</ul>
</li>
<li>
<p>周期</p>
<ul>
<li>振动一次 时间</li>
</ul>
</li>
<li>
<p>波长</p>
<ul>
<li>
<p>周期内 声波传播距离</p>
</li>
<li>
<p>低频 波长长 各向均匀传播</p>
</li>
<li>
<p>高频 向前直射</p>
</li>
<li>
<p>遇到阻碍物 衍射</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="设备">设备</h2>
<ul>
<li>
<p>声卡</p>
</li>
<li>
<p>耳机</p>
</li>
<li>
<p>音箱</p>
</li>
<li>
<p>麦克风</p>
</li>
<li>
<p>MIDI键盘</p>
<ul>
<li>music instrument digital interface<img src="https://api2.mubu.com/v3/document_image/0AE3412B980643DB1620962751.jpg" alt="img" loading="lazy"></li>
</ul>
</li>
</ul>
<h2 id="数字化">数字化</h2>
<ul>
<li>
<p>模拟音频</p>
<ul>
<li>录制 振动产生声音 存于介质（磁带），电信号</li>
</ul>
</li>
<li>
<p>数字音频</p>
<ul>
<li>二进制 离散 信号</li>
</ul>
</li>
<li>
<p>步骤</p>
<ul>
<li>如图<img src="https://api2.mubu.com/v3/document_image/55454862D2E6487E1620963067.jpg" alt="img" loading="lazy"></li>
</ul>
</li>
<li>
<p>概念</p>
<ul>
<li>
<p>采样</p>
</li>
<li>
<p>采样频率</p>
</li>
<li>
<p>采样定理</p>
</li>
<li>
<p>量化</p>
</li>
<li>
<p>量化位数</p>
</li>
<li>
<p>量化深度</p>
</li>
<li>
<p>编码</p>
</li>
<li>
<p>波形编码</p>
</li>
<li>
<p>参数编码</p>
</li>
<li>
<p>感知编码</p>
</li>
<li>
<p>声道数</p>
</li>
<li>
<p>质量 数据量</p>
</li>
</ul>
</li>
<li>
<p>数据存储量 计算</p>
<ul>
<li>如图<img src="https://api2.mubu.com/v3/document_image/EF9F02F87FD94FA81620963604.jpg" alt="img" loading="lazy"></li>
</ul>
</li>
<li>
<p>指标参考</p>
<ul>
<li>
<p>采样频率 间隔短</p>
</li>
<li>
<p>量化深度 等级多</p>
</li>
<li>
<p>音频码流率 大</p>
</li>
</ul>
</li>
</ul>
<h2 id="语音机理">语音机理</h2>
<ul>
<li>
<p>语音生成</p>
<ul>
<li>如图<img src="https://api2.mubu.com/v3/document_image/1018932E17A844251620964997.jpg" alt="img" loading="lazy"></li>
</ul>
</li>
<li>
<p>共振峰</p>
<ul>
<li>声道具有一组共振频率</li>
</ul>
</li>
<li>
<p>感知</p>
<ul>
<li>
<p>听域 听阈</p>
<ul>
<li>感知声音范围 ； 听到最低声压</li>
</ul>
</li>
<li>
<p>响度</p>
</li>
<li>
<p>掩蔽效应</p>
<ul>
<li>声音听阈 因 另一个声音 出现升高</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="信号模型">信号模型</h2>
<ul>
<li>
<p>激励模型</p>
<ul>
<li>基音为周期 斜三角脉冲串</li>
</ul>
</li>
<li>
<p>调制模型</p>
<ul>
<li>无损声管模型 共振锋模型</li>
</ul>
</li>
<li>
<p>辐射模型</p>
</li>
<li>
<p>数字模型</p>
<ul>
<li>
<p>如图<img src="https://api2.mubu.com/v3/document_image/07F0AE21876F46111620965630.jpg" alt="img" loading="lazy"></p>
</li>
<li>
<p>局限</p>
<ul>
<li>声门 声道 耦合 非线性</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="语音分析">语音分析</h2>
<ul>
<li>
<p>短时时域信息</p>
<ul>
<li>
<p>预处理</p>
<ul>
<li>
<p>预加重</p>
</li>
<li>
<p>分帧</p>
</li>
<li>
<p>加窗处理</p>
</li>
</ul>
</li>
<li>
<p>分析</p>
<ul>
<li>
<p>短时能量</p>
</li>
<li>
<p>平均幅度</p>
</li>
<li>
<p>短时平均过零率</p>
</li>
<li>
<p>短时自相关函数</p>
</li>
<li>
<p>短时平均幅度差</p>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>短时频域倒谱分析</p>
<ul>
<li>短时傅立叶变换</li>
</ul>
</li>
<li>
<p>语谱图</p>
<ul>
<li>
<p>如图<img src="https://api2.mubu.com/v3/document_image/8AFFCB8C4C05478E1620965992.jpg" alt="img" loading="lazy"></p>
</li>
<li>
<p>1941 贝尔实验室</p>
</li>
<li>
<p>三维显示频谱特性</p>
</li>
<li>
<p>生成</p>
<ul>
<li>
<p>采样</p>
<ul>
<li>连续-离散</li>
</ul>
</li>
<li>
<p>预加重</p>
</li>
<li>
<p>分帧</p>
<ul>
<li>不定长 分为 固定长度 小段</li>
</ul>
</li>
<li>
<p>加窗</p>
</li>
<li>
<p>使分帧端点不突变</p>
</li>
<li>
<p>变换</p>
<ul>
<li>
<p>频谱坐标化</p>
</li>
<li>
<p>逆时针旋转坐标</p>
</li>
<li>
<p>幅度映射颜色</p>
</li>
</ul>
</li>
<li>
<p>拼接</p>
</li>
</ul>
</li>
<li>
<p>宽带 窄带 语谱图</p>
</li>
</ul>
</li>
</ul>
<h2 id="技术">技术</h2>
<ul>
<li>
<p>语音合成</p>
<ul>
<li>
<p>波形编码</p>
</li>
<li>
<p>参数分析</p>
</li>
<li>
<p>应用</p>
<ul>
<li>文语转换</li>
</ul>
</li>
</ul>
</li>
<li>
<p>语音增强</p>
<ul>
<li>
<p>噪声对消</p>
</li>
<li>
<p>谐波增强</p>
</li>
<li>
<p>参数估计</p>
</li>
</ul>
</li>
<li>
<p>语音识别</p>
<ul>
<li>如图<img src="https://api2.mubu.com/v3/document_image/B32FB5C02352430E1620966231.jpg" alt="img" loading="lazy"></li>
</ul>
</li>
</ul>
<h1 id="数字视频技术-专题四">数字视频技术 专题四</h1>
<h2 id="视频概念">视频概念</h2>
<ul>
<li>
<p>动态图像</p>
</li>
<li>
<p>数字视频</p>
<ul>
<li>
<p>视觉暂留</p>
<ul>
<li>24帧
<ul>
<li>人员无法辨别静帧 有平滑感觉</li>
</ul>
</li>
</ul>
</li>
<li>
<p>数字电视 1990 DTV digital TV</p>
</li>
<li>
<p>帧率 fps 帧/s</p>
<ul>
<li>frame per second</li>
</ul>
</li>
</ul>
</li>
<li>
<p>模拟视频</p>
<ul>
<li>
<p>电视台广播信号</p>
</li>
<li>
<p>连续</p>
</li>
<li>
<p>标准</p>
<ul>
<li>
<p>NTSC</p>
<ul>
<li>national television standard committee</li>
</ul>
</li>
<li>
<p>PAL</p>
<ul>
<li>phase alternating line</li>
</ul>
</li>
<li>
<p>SECAM</p>
<ul>
<li>
<p>sequential color memory</p>
</li>
<li>
<p>东欧 法国</p>
</li>
</ul>
</li>
<li>
<p>以上互不兼容</p>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>隔行扫描 逐行扫描</p>
<ul>
<li>
<p>逐行帧</p>
<ul>
<li>奇数行 偶数行 同时间 采样</li>
</ul>
</li>
<li>
<p>隔行帧</p>
<ul>
<li>奇数 偶数 不同时间 采样</li>
</ul>
</li>
<li>
<p>顶场</p>
<ul>
<li>隔行帧 偶数行</li>
</ul>
</li>
<li>
<p>底场</p>
<ul>
<li>隔行帧 奇数行</li>
</ul>
</li>
<li>
<p>逐行视频</p>
<ul>
<li>逐行帧 视频序列</li>
</ul>
</li>
<li>
<p>隔行视频</p>
<ul>
<li>隔行帧 视频序列</li>
</ul>
</li>
<li>
<p>对比</p>
<ul>
<li>相同数据量 隔行采样 增加采样率 ， 时域运动平滑</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="视频-获取-编辑">视频 获取 编辑</h2>
<ul>
<li>
<p>视频采集（捕捉）卡</p>
<ul>
<li>
<p>video capture card</p>
</li>
<li>
<p>对信号采集 量化 压缩编码为数据视频流</p>
</li>
</ul>
</li>
<li>
<p>摄像机</p>
<ul>
<li>
<p>镜头</p>
</li>
<li>
<p>CCD</p>
</li>
<li>
<p>数字信号处理DSP芯片</p>
</li>
<li>
<p>存储器</p>
</li>
<li>
<p>显示器 LCD</p>
</li>
</ul>
</li>
<li>
<p>质量评估</p>
<ul>
<li>
<p>峰值信噪比 peak signal noise ratio PSNR</p>
<ul>
<li>均方误差越小 峰值信噪比越大 失真越小</li>
</ul>
</li>
<li>
<p>结构相似度 structure similarity index SSIM</p>
</li>
<li>
<p>多尺度结构相似度 multi scale structural similarity index MS-SSIM</p>
</li>
</ul>
</li>
</ul>
<h2 id="运动估计">运动估计</h2>
<ul>
<li>
<p>光流</p>
<ul>
<li>对象/相机移动，两连续帧间 明显运动模式</li>
</ul>
</li>
<li>
<p>块匹配</p>
<ul>
<li>
<p>基于运动准则 参考帧和当前帧 尺寸匹配</p>
</li>
<li>
<p>穷举</p>
</li>
</ul>
</li>
</ul>
<h2 id="编码标准">编码标准</h2>
<ul>
<li>
<p>AVI</p>
<ul>
<li>video for windows</li>
</ul>
</li>
<li>
<p>MOV</p>
<ul>
<li>quick time for windows</li>
</ul>
</li>
<li>
<p>MPG</p>
<ul>
<li>mpeg压缩</li>
</ul>
</li>
<li>
<p>DAT</p>
<ul>
<li>VCD mpeg压缩</li>
</ul>
</li>
</ul>
<h1 id="数字媒体压缩技术-专题五">数字媒体压缩技术 专题五</h1>
<h2 id="数据压缩">数据压缩</h2>
<ul>
<li>
<p>数据冗余</p>
<ul>
<li>
<p>数据计算</p>
<ul>
<li>如图<img src="https://api2.mubu.com/v3/document_image/1C5E3835137C47D21620793130.jpg" alt="img" loading="lazy"></li>
</ul>
</li>
<li>
<p>空间</p>
<ul>
<li>
<p>重复的像素</p>
</li>
<li>
<p>较少编码 表示 原数据</p>
</li>
<li>
<p>基础</p>
<ul>
<li>
<p>变换编码</p>
</li>
<li>
<p>量化</p>
</li>
<li>
<p>熵编码</p>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>时间</p>
<ul>
<li>
<p>相邻帧 相似性</p>
</li>
<li>
<p>预测 ，运动补偿 压缩</p>
</li>
</ul>
</li>
<li>
<p>结构</p>
<ul>
<li>
<p>纹理结构</p>
</li>
<li>
<p>自相似性</p>
</li>
</ul>
</li>
<li>
<p>视觉</p>
<ul>
<li>
<p>对 某种信号颜色 不敏感</p>
</li>
<li>
<p>视觉惰性</p>
<ul>
<li>
<p>蓝色 红绿色</p>
</li>
<li>
<p>25帧采样</p>
</li>
<li>
<p>遮蔽效应</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>压缩比（压缩率）计算 想对数据冗余计算</p>
<ul>
<li>如图<img src="https://api2.mubu.com/v3/document_image/E4ADA48E8D594D2F1620793711.jpg" alt="img" loading="lazy"></li>
</ul>
</li>
<li>
<p>压缩分类</p>
<ul>
<li>
<p>如图</p>
<figure data-type="image" tabindex="1"><img src="C:%5CUsers%5Clenovo%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20210517163438935.png" alt="image-20210517163438935" loading="lazy"></figure>
<ul>
<li>
<p>统计（熵）</p>
<ul>
<li>
<p>无记忆信源</p>
</li>
<li>
<p>根据 码字概率 压缩</p>
</li>
<li>
<p>寻找 码字长度 概率 最优匹配</p>
</li>
</ul>
</li>
<li>
<p>预测</p>
<ul>
<li>空间 相邻数据 相关性 压缩数据</li>
</ul>
</li>
<li>
<p>变换</p>
<ul>
<li>时域-&gt;频域</li>
</ul>
</li>
<li>
<p>分析-合成</p>
<ul>
<li>分析 源数据 提取特征参数（基元）
<ul>
<li>编码 仅对 特征参数（基元）</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>无损压缩</p>
<ul>
<li>
<p>如图<img src="https://api2.mubu.com/v3/document_image/2D4333941D4141681620795543.jpg" alt="img" loading="lazy"></p>
</li>
<li>
<p>例如</p>
<ul>
<li>
<p>Huffman</p>
</li>
<li>
<p>行程</p>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>有损压缩</p>
<ul>
<li>如图<img src="https://api2.mubu.com/v3/document_image/6455BBBEF36F40261620795547.jpg" alt="img" loading="lazy"></li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="压缩编码">压缩编码</h2>
<ul>
<li>
<p>理论基础</p>
<ul>
<li>
<p>信息论</p>
</li>
<li>
<p>信息熵</p>
<ul>
<li>熵
<ul>
<li>某事出现消息越多 出现概率越小</li>
</ul>
</li>
</ul>
</li>
<li>
<p>信息量</p>
<ul>
<li>如图<img src="https://api2.mubu.com/v3/document_image/8279F119E7E245151620796424.jpg" alt="img" loading="lazy"></li>
</ul>
</li>
<li>
<p>平均码字长度</p>
<ul>
<li>如图<img src="https://api2.mubu.com/v3/document_image/9C06809D5DD14D5A1620796168.jpg" alt="img" loading="lazy"><img src="https://api2.mubu.com/v3/document_image/CB9AB00E47CB4C631620796277.jpg" alt="img" loading="lazy"></li>
</ul>
</li>
<li>
<p>编码效率</p>
<ul>
<li>如图<img src="https://api2.mubu.com/v3/document_image/78B80273C5804B381620796464.jpg" alt="img" loading="lazy"></li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="熵编码">熵编码</h3>
<ul>
<li>
<p>变长最佳编码</p>
<ul>
<li>
<p>概率大 信息符号 短码字</p>
</li>
<li>
<p>​          小                      长码字</p>
</li>
<li>
<p>Huffman理论基础</p>
</li>
</ul>
</li>
</ul>
<h3 id="huffman">Huffman</h3>
<ul>
<li>
<p>举例计算</p>
<ul>
<li>如图<img src="https://api2.mubu.com/v3/document_image/AA26B537B78442CF1620799178.jpg" alt="img" loading="lazy"><img src="https://api2.mubu.com/v3/document_image/95FCA21EE6F444C91620799178.jpg" alt="img" loading="lazy"><img src="https://api2.mubu.com/v3/document_image/54DE2AA881FD48F71620799178.jpg" alt="img" loading="lazy"><img src="https://api2.mubu.com/v3/document_image/9CCA9FBA072F44CC1620799178.jpg" alt="img" loading="lazy"></li>
</ul>
</li>
<li>
<p>适用于 概率分布不均匀 信源</p>
</li>
</ul>
<h3 id="游程编码">游程编码</h3>
<ul>
<li>
<p>游程灰度 行程长度 代替 游程本身</p>
</li>
<li>
<p>举例计算</p>
<ul>
<li>如图<img src="https://api2.mubu.com/v3/document_image/981E43A811774FA41620799508.jpg" alt="img" loading="lazy"></li>
</ul>
</li>
<li>
<p>二维游程编码</p>
<ul>
<li>
<p>扫描 二维转一维</p>
<ul>
<li>
<p>如图<img src="https://api2.mubu.com/v3/document_image/3B9723DEBCAD49C71620799729.jpg" alt="img" loading="lazy"></p>
</li>
<li>
<p>练习 计算<img src="https://api2.mubu.com/v3/document_image/0C33BD13E0CA43CA1620800390.jpg" alt="img" loading="lazy"></p>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>分析</p>
<ul>
<li>
<p>适合 大面积色块</p>
<ul>
<li>
<p>例如 传真 白色多 黑色少 计算</p>
<ul>
<li>
<p>500w 3b 3000w 12b</p>
<ul>
<li>
<p>w :white b:black</p>
</li>
<li>
<p>由于 2048&lt;3000&lt;4096</p>
<ul>
<li>
<p>黑白统一分配，计数需要12bits（2的12次方）</p>
</li>
<li>
<p>若不统一分配</p>
<ul>
<li>
<p>黑色：4bits</p>
</li>
<li>
<p>白色：12bits</p>
</li>
<li>
<p>则数字部分编码位数：12，4，12，4</p>
</li>
<li>
<p>数字部分字节数：12x2+4x2</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>不适合 复杂图像</p>
</li>
</ul>
</li>
</ul>
<h3 id="预测编码dpcm">预测编码（DPCM）</h3>
<ul>
<li>
<p>相邻像素 信息冗余</p>
</li>
<li>
<p>过程</p>
<ul>
<li>如图<img src="https://api2.mubu.com/v3/document_image/5FCA5EE927A744821620800878.jpg" alt="img" loading="lazy"></li>
</ul>
</li>
<li>
<p>举例计算</p>
<ul>
<li>如图<img src="https://api2.mubu.com/v3/document_image/36ECC5725BF64CD41620800951.jpg" alt="img" loading="lazy"></li>
</ul>
</li>
</ul>
<h3 id="变换编码">变换编码</h3>
<ul>
<li>
<p>过程</p>
<ul>
<li>如图<img src="https://api2.mubu.com/v3/document_image/423B127BB32944141620801153.jpg" alt="img" loading="lazy"></li>
</ul>
</li>
<li>
<p>举例</p>
<ul>
<li>如图<img src="https://api2.mubu.com/v3/document_image/CD85FFFFCD3647891620801341.jpg" alt="img" loading="lazy"></li>
</ul>
</li>
</ul>
<h3 id="混合编码">混合编码</h3>
<ul>
<li>举例计算
<ul>
<li>如图<img src="https://api2.mubu.com/v3/document_image/6CBCA9906AC147EE1620802928.jpg" alt="img" loading="lazy"><img src="https://api2.mubu.com/v3/document_image/90D5404E9A7843BC1620802928.jpg" alt="img" loading="lazy"></li>
</ul>
</li>
</ul>
<h2 id="动态图像压缩">动态图像压缩</h2>
<ul>
<li>
<p>视频图像编码标准</p>
<ul>
<li>
<p>如图<img src="https://api2.mubu.com/v3/document_image/D374EBC36D184CEE1620884374.jpg" alt="img" loading="lazy"></p>
</li>
<li>
<p>国际标准化组织</p>
<ul>
<li>
<p>JPEG</p>
<ul>
<li>joint photographic experts group</li>
</ul>
</li>
<li>
<p>MPEG</p>
<ul>
<li>motion picture experts group</li>
</ul>
</li>
<li>
<p>VCEG</p>
<ul>
<li>video coding experts group</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>jpeg压缩编码</p>
<ul>
<li>
<p>无损压缩</p>
<ul>
<li>差分冒充调制 DPCM</li>
</ul>
</li>
<li>
<p>有损压缩</p>
<ul>
<li>
<p>离散余弦变换 DCT</p>
</li>
<li>
<p>如图<img src="https://api2.mubu.com/v3/document_image/AE9E72632393478B1620884837.jpg" alt="img" loading="lazy"></p>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>视频编码</p>
<ul>
<li>
<p>解码</p>
<ul>
<li>预测 - 变换 - 量化 - 熵编码 - 环路滤波</li>
</ul>
</li>
<li>
<p>压缩</p>
<ul>
<li>
<p>帧内压缩</p>
<ul>
<li>
<p>图像压缩</p>
</li>
<li>
<p>每帧 独立编码</p>
<ul>
<li>不依赖 前后帧</li>
</ul>
</li>
</ul>
</li>
<li>
<p>帧间压缩</p>
<ul>
<li>利用 数据 时域冗余
<ul>
<li>运动补偿变换编码</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>分快编码 每一块一个单元</p>
<ul>
<li>分快后 自上而下 自左向右 对每单元处理</li>
</ul>
</li>
<li>
<p>码流结构（自上而下）</p>
<ul>
<li>
<p>MPEG流（mpeg stream）</p>
</li>
<li>
<p>图像组 （GOP group of pictures）</p>
</li>
<li>
<p>图像（image）</p>
</li>
<li>
<p>宏块（Marco block）</p>
</li>
<li>
<p>块（block）</p>
</li>
</ul>
</li>
<li>
<p>标准</p>
<ul>
<li>
<p>mpeg1</p>
<ul>
<li>1992</li>
</ul>
</li>
<li>
<p>mpeg2</p>
</li>
</ul>
</li>
<li>
<p>技术</p>
<ul>
<li>
<p>采样</p>
<ul>
<li>YCbCr比rgb 更好压缩</li>
</ul>
</li>
<li>
<p>预测</p>
<ul>
<li>
<p>1952</p>
</li>
<li>
<p>差值脉冲编码调制</p>
</li>
<li>
<p>帧内预测（消除 空域 冗余）</p>
</li>
<li>
<p>帧间                          时域</p>
</li>
<li>
<p>运动图像 临近帧 相关性</p>
<ul>
<li>空间位置 相对偏移量 运动矢量</li>
</ul>
</li>
</ul>
</li>
<li>
<p>变换</p>
<ul>
<li>
<p>正交变换 去除 空间像素 相关性</p>
<ul>
<li>
<p>变换后 频域系数 使 图像紧凑</p>
</li>
<li>
<p>能量 集中 低频区域</p>
</li>
<li>
<p>举例</p>
<ul>
<li>
<p>K-L(Karhunen-Loeve)</p>
</li>
<li>
<p>DCT</p>
</li>
<li>
<p>DWT(wavelet 小波）</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>量化</p>
<ul>
<li>
<p>降低 数据精度 减少编码量</p>
</li>
<li>
<p>矢量量化 标量量化</p>
</li>
<li>
<p>有损压缩 失真</p>
</li>
<li>
<p>调整量化步长 调整图像质量</p>
</li>
</ul>
</li>
<li>
<p>熵编码</p>
<ul>
<li>
<p>去除 信源符号 信息冗余</p>
</li>
<li>
<p>信息熵原理 压缩</p>
</li>
</ul>
</li>
<li>
<p>mpeg4 基于对象编码</p>
<ul>
<li>
<p>依赖 场景 任意形状 对象检测 编码</p>
</li>
<li>
<p>AV对象（Audio/Visual）</p>
<ul>
<li>
<p>知识产权保护</p>
</li>
<li>
<p>表示 听觉 视觉 视听组合</p>
</li>
<li>
<p>允许组合</p>
</li>
</ul>
</li>
<li>
<p>分割与编码</p>
<ul>
<li>如图<img src="https://api2.mubu.com/v3/document_image/AFAA9DB1282B49B11620887633.jpg" alt="img" loading="lazy"></li>
</ul>
</li>
<li>
<p>视频对象平面 VOP video object plane</p>
<ul>
<li>视频某一时刻采样</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="h26x标准">H26.x标准</h2>
<ul>
<li>
<p>h261 1990 h263 1995</p>
</li>
<li>
<p>h264 mepg4 part10 高级视频编码</p>
</li>
<li>
<p>特点</p>
<ul>
<li>
<p>提高效率</p>
</li>
<li>
<p>提告网络适应</p>
</li>
</ul>
</li>
<li>
<p>技术</p>
<ul>
<li>
<p>分层设计</p>
</li>
<li>
<p>高精度 多模式 运动估计</p>
</li>
<li>
<p>4x4整数变换</p>
</li>
<li>
<p>统一VLC</p>
</li>
<li>
<p>帧内预测</p>
</li>
<li>
<p>切换帧（SP SI）</p>
</li>
<li>
<p>面向IP、无线环境</p>
</li>
</ul>
</li>
</ul>
<h2 id="avs-audio-video-standards">AVS audio video standards</h2>
<ul>
<li>
<p>我国自主制定标准</p>
</li>
<li>
<p>目标</p>
<ul>
<li>媒体数据压缩至原 百分之一</li>
</ul>
</li>
<li>
<p>技术</p>
<ul>
<li>
<p>整数变换（8x8）</p>
</li>
<li>
<p>量化</p>
</li>
<li>
<p>帧内预测</p>
</li>
<li>
<p>像素插值</p>
</li>
<li>
<p>运动补偿（帧间）</p>
</li>
<li>
<p>熵编码（二维）</p>
</li>
<li>
<p>环内滤波</p>
</li>
</ul>
</li>
</ul>
<h1 id="多媒体数据安全-专题六">多媒体数据安全 专题六</h1>
<h2 id="隐写术">隐写术</h2>
<ul>
<li>
<p>信息 嵌入 媒体数据 传送</p>
</li>
<li>
<p>隐藏消息 -&gt;  隐蔽通信</p>
</li>
<li>
<p>对抗式研究：信息隐藏 &lt;-&gt; 信息隐藏分析</p>
</li>
</ul>
<h2 id="数字水印">数字水印</h2>
<ul>
<li>
<p>标识信息 （如数字水印）嵌入 数字载体 （媒体，文档）</p>
</li>
<li>
<p>不影响 原载体 使用价值</p>
</li>
<li>
<p>不容易 探知 修改</p>
</li>
<li>
<p>生产方 易识别</p>
</li>
<li>
<p>保护版权 信息安全 防伪溯源</p>
</li>
</ul>
<h2 id="多媒体取证">多媒体取证</h2>
<ul>
<li>
<p>多媒体 原始性鉴别</p>
</li>
<li>
<p>无损取证溯源</p>
<ul>
<li>
<p>对 篡改内容 取证</p>
</li>
<li>
<p>对 多媒体设备 溯源分析</p>
</li>
</ul>
</li>
</ul>
<h2 id="多媒体感知哈希">多媒体感知哈希</h2>
<ul>
<li>
<p>多媒体数据集 映射 感知特征集</p>
</li>
<li>
<p>多媒体数据 &lt;-&gt;  “指纹”（特征）数据</p>
<ul>
<li>图像相似&lt;-&gt;指纹（特征）相似</li>
</ul>
</li>
</ul>
<h2 id="多媒体内容隐私">多媒体内容隐私</h2>
<ul>
<li>
<p>保护敏感内容</p>
</li>
<li>
<p>图像</p>
<ul>
<li>
<p>访问权限控制</p>
<ul>
<li>
<p>可见范围</p>
</li>
<li>
<p>有效期</p>
</li>
</ul>
</li>
<li>
<p>重要信息 特殊编码</p>
</li>
</ul>
</li>
<li>
<p>视频</p>
<ul>
<li>
<p>保护 数据源 编码过程</p>
</li>
<li>
<p>保护隐私 不影响观看</p>
</li>
<li>
<p>保护目标</p>
<ul>
<li>
<p>身份</p>
</li>
<li>
<p>人脸</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="案例">案例</h2>
<h3 id="基于图像信息隐藏">基于图像信息隐藏</h3>
<ul>
<li>
<p>心理 视觉欺骗（所见即所得）-&gt; 秘密信息 位于 对图像影响小的位置</p>
</li>
<li>
<p>提取方法 还原 秘密信息</p>
</li>
<li>
<p>技术指标</p>
<ul>
<li>
<p>隐蔽性</p>
</li>
<li>
<p>鲁棒性</p>
</li>
<li>
<p>安全性</p>
</li>
<li>
<p>对称性</p>
</li>
<li>
<p>可纠错</p>
</li>
<li>
<p>效率</p>
</li>
</ul>
</li>
<li>
<p>技术</p>
<ul>
<li>
<p>空间域</p>
<ul>
<li>
<p>原始像素 嵌入信息</p>
</li>
<li>
<p>最低有效位 LSB</p>
<ul>
<li>隐藏信息 -&gt; 宿主最低有效位</li>
</ul>
</li>
</ul>
</li>
<li>
<p>变换域</p>
<ul>
<li>
<p>隐藏信息 图像高频分量</p>
<ul>
<li>人眼 高频 不敏感</li>
</ul>
</li>
<li>
<p>扩频隐藏</p>
</li>
<li>
<p>DCT隐藏</p>
</li>
<li>
<p>小波隐藏</p>
</li>
</ul>
</li>
<li>
<p>融合</p>
<ul>
<li>
<p>利用 图像 相关性  ，放大 原始公开图像 隐藏 三副与公开图像 大小一样的数字图像</p>
</li>
<li>
<p>彩色图像 实用</p>
</li>
</ul>
</li>
<li>
<p>量化噪声伪装</p>
<ul>
<li>
<p>通过 控制量化等级 嵌入 图像数据流</p>
<ul>
<li>
<p>嵌入数据 相对 原图 类似噪声</p>
</li>
<li>
<p>不易发现</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="基于音频信息隐藏">基于音频信息隐藏</h3>
<ul>
<li>
<p>音频载体 对人耳 不敏感的音频参数</p>
</li>
<li>
<p>技术指标</p>
<ul>
<li>
<p>鲁棒性</p>
</li>
<li>
<p>安全性</p>
</li>
<li>
<p>透明性</p>
</li>
<li>
<p>不可检测</p>
</li>
</ul>
</li>
<li>
<p>技术</p>
<ul>
<li>
<p>时域</p>
<ul>
<li>
<p>对 音频信号 幅度 / 文件结构 处理</p>
</li>
<li>
<p>LSB隐藏</p>
</li>
<li>
<p>回声隐藏</p>
</li>
<li>
<p>音频文件结构隐藏</p>
</li>
</ul>
</li>
<li>
<p>频域</p>
<ul>
<li>
<p>离散傅立叶变换 -&gt; 频域特征处理 -&gt; 信息嵌入</p>
<ul>
<li>
<p>LSB</p>
</li>
<li>
<p>扩频</p>
</li>
<li>
<p>相位</p>
</li>
<li>
<p>频带分隔</p>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>离散余弦变换域（DCT）</p>
<ul>
<li>
<p>DCT变换-&gt;DCT系数操作-&gt;信息嵌入</p>
</li>
<li>
<p>对 数模、模数转换 抵抗力强</p>
</li>
</ul>
</li>
<li>
<p>小波域</p>
</li>
<li>
<p>压缩域</p>
</li>
</ul>
</li>
</ul>
<h3 id="基于视频信息隐藏">基于视频信息隐藏</h3>
<ul>
<li>
<p>原始视频</p>
<ul>
<li>秘密信息 嵌入 元数据 -&gt; 压缩编码</li>
</ul>
</li>
<li>
<p>压缩域</p>
<ul>
<li>
<p>解码 -&gt; 编码过程 嵌入 信息</p>
</li>
<li>
<p>技术</p>
<ul>
<li>
<p>联合预测误差 隐藏</p>
</li>
<li>
<p>MPEG压缩域 隐藏</p>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>码流域</p>
<ul>
<li>
<p>信息 嵌入 压缩 码流</p>
</li>
<li>
<p>接收方 从 码流 提取 秘密信息</p>
</li>
<li>
<p>技术</p>
<ul>
<li>MPEG4 纹理编码 隐藏</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="基于jpeg压缩-数字水印">基于jpeg压缩 数字水印</h3>
<ul>
<li>
<p>算法流程</p>
<ul>
<li>
<p>图像分割 8x8 不重叠 图像块（后续单独处理）</p>
<ul>
<li>如图<img src="https://api2.mubu.com/v3/document_image/10C18BD3642B42C31620792106.jpg" alt="img" loading="lazy"></li>
</ul>
</li>
<li>
<p>颜色空间转换 RGB-&gt;YCbCr</p>
<ul>
<li>如图<img src="https://api2.mubu.com/v3/document_image/D248CEF79F254CF81620792119.jpg" alt="img" loading="lazy"></li>
</ul>
</li>
<li>
<p>Y：离散余弦变换</p>
<ul>
<li>
<p>DCT变换的图像数据</p>
<ul>
<li>
<p>DC 直流系数</p>
<ul>
<li>图像主要区域</li>
</ul>
</li>
<li>
<p>AC 交流系数</p>
<ul>
<li>图像轮廓细节</li>
</ul>
</li>
</ul>
</li>
<li>
<p>如图<img src="https://api2.mubu.com/v3/document_image/16886BDDEF2241A81620792129.jpg" alt="img" loading="lazy"></p>
</li>
</ul>
</li>
<li>
<p>数据量化</p>
<ul>
<li>
<p>根据量化表计算 公式：B=G/Q</p>
<ul>
<li>
<p>B：量化后结果</p>
</li>
<li>
<p>G：输入值</p>
</li>
<li>
<p>Q：量化系数</p>
</li>
</ul>
</li>
<li>
<p>如图<img src="https://api2.mubu.com/v3/document_image/E0D776EB83734CDC1620792139.jpg" alt="img" loading="lazy"></p>
</li>
</ul>
</li>
<li>
<p>嵌入信息 Y 放回 YCbCr -&gt; RGB</p>
<ul>
<li>
<p>嵌入原理</p>
<ul>
<li>
<p>低频分量</p>
<ul>
<li>
<p>图像的主要信息</p>
</li>
<li>
<p>决定灰度等级</p>
</li>
</ul>
</li>
<li>
<p>中频分量</p>
<ul>
<li>图像的基本结构</li>
</ul>
</li>
<li>
<p>高频分量</p>
<ul>
<li>边缘和细节</li>
</ul>
</li>
<li>
<p>如图<img src="https://api2.mubu.com/v3/document_image/4A23CF4D0C9941771620792169.jpg" alt="img" loading="lazy"></p>
</li>
</ul>
</li>
<li>
<p>如图<img src="https://api2.mubu.com/v3/document_image/96E752123D634C501620792174.jpg" alt="img" loading="lazy"></p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[目录]]></title>
        <id>https://logic-three-body.github.io/post/mu-lu/</id>
        <link href="https://logic-three-body.github.io/post/mu-lu/">
        </link>
        <updated>2021-05-11T04:16:04.000Z</updated>
        <content type="html"><![CDATA[<h2 id="计算机图形学">计算机图形学</h2>
<h3 id="渲染器基础">渲染器基础</h3>
<h4 id="tinyrendergames101光栅化系列">tinyrender+GAMES101光栅化系列</h4>
<h5 id="games101-assignment1-transform"><a href="https://logic-three-body.github.io/post/games101-greaterassignment1-transform/">GAMES101-&gt;assignment1 Transform</a></h5>
<h5 id="tinyrender之旅-渲染管线探秘"><a href="https://logic-three-body.github.io/post/tinyrender-zhi-lu-greater-xuan-ran-guan-xian-tan-mi/">TinyRender之旅 -&gt; 渲染管线探秘</a></h5>
<h5 id="games101-assignment3-shader-and-graphic-pipeline"><a href="https://logic-three-body.github.io/post/games101-greaterassignment3-shader-and-graphic-pipeline/">GAMES101-&gt;assignment3 Shader and Graphic pipeline</a></h5>
<h4 id="tinyraytracegames101光线追踪系列">tinyraytrace+GAMES101光线追踪系列</h4>
<h3 id="webgl与threejs">WebGL与THREEJS</h3>
<h4 id="webgl-threejs-example-研究">WebGL three.js-example 研究</h4>
<h5 id="misc_controls_pointerlock-漫游"><a href="https://logic-three-body.github.io/post/webgl-threejs-example-yan-jiu-misc_controls_pointerlock/">misc_controls_pointerlock 漫游</a></h5>
<h5 id="threejs-shader-实现phong光照模型"><a href="https://logic-three-body.github.io/post/threejs-shader-shi-xian-phong-guang-zhao-mo-xing/">THREE.JS shader 实现Phong光照模型</a></h5>
<h5 id="webgl-shader-实现phong光照模型"><a href="https://logic-three-body.github.io/post/webgl-shader-shi-xian-phong-guang-zhao-mo-xing/">WebGL shader 实现Phong光照模型</a></h5>
<h4 id="games202高质量实时渲染">GAMES202高质量实时渲染</h4>
<h5 id="assignment1-realtime-shadow"><a href="https://logic-three-body.github.io/post/games202-zuo-ye-1/">assignment1 realtime shadow</a></h5>
<h5 id="assignment2-precoumpute-radiance-transfer"><a href="https://logic-three-body.github.io/post/assignment2-precoumpute-radiance-transfer/">assignment2 precoumpute radiance transfer</a></h5>
<h5 id="assignment3-screen-space-raytracing"><a href="https://logic-three-body.github.io/post/assignment3-screen-space-raytracing/">assignment3 screen space raytracing</a></h5>
<h2 id="专业课复习笔记">专业课复习笔记</h2>
<h3 id="数字媒体技术期末总结"><a href="https://logic-three-body.github.io/post/shu-zi-mei-ti-ji-zhu-qi-mo-zong-jie/">数字媒体技术期末总结</a></h3>
<h3 id="数字图像处理期末总结"><a href="https://logic-three-body.github.io/post/shu-zi-tu-xiang-chu-li-zhi-shi-zong-jie/">数字图像处理期末总结</a></h3>
]]></content>
    </entry>
</feed>